{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proposed.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaguPandya96/Research-Project-Fall-2020/blob/master/Proposed%20Work%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do3uVXAdf0YX",
        "outputId": "e556f12a-9385-4ea7-f193-aa16601ebfe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "#Hirarchical Attention Reset After Done\n",
        "!pip install tensorflow==1.11.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/d5/38cd4543401708e64c9ee6afa664b936860f4630dd93a49ab863f9998cd2/tensorflow-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (63.0MB)\n",
            "\u001b[K     |████████████████████████████████| 63.0MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (1.1.0)\n",
            "Collecting keras-applications>=1.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (3.12.4)\n",
            "Collecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 53.5MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.12.0,>=1.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (0.35.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0) (0.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.5->tensorflow==1.11.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0) (3.2.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.17.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, setuptools, tensorboard, tensorflow\n",
            "  Found existing installation: setuptools 50.3.0\n",
            "    Uninstalling setuptools-50.3.0:\n",
            "      Successfully uninstalled setuptools-50.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 setuptools-39.1.0 tensorboard-1.11.0 tensorflow-1.11.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiO-6o7fgC7U",
        "outputId": "85d69439-4e49-4719-fd6e-20faf76fc22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install keras==2.1.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\r\u001b[K     |█                               | 10kB 7.2MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to5H5OFAw_sy",
        "outputId": "072ebbdc-44a8-4798-89e1-9a5106cf716e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import random as rr\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "from itertools import chain\n",
        "from gensim.models import Word2Vec\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import GRU, Bidirectional, TimeDistributed, CuDNNLSTM, LSTM, Dropout, CuDNNGRU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import  RMSprop\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from keras import backend as K\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.engine.topology import Layer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycQgrK-pAjBv",
        "outputId": "66a8be13-f346-42f1-f088-3879507f1c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#load data\n",
        "DATA_PATH1 = '/content/drive/My Drive/Colab Notebooks/chromium.csv'\n",
        "data1 = pd.read_csv(DATA_PATH1, sep='\\t')\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Data\")\n",
        "data_top1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Define a way to enforce performance constraint...</td>\n",
              "      <td>\\nThere are cases where tests should fail if a...</td>\n",
              "      <td>Bug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Websites that don't work with Chrome Browser</td>\n",
              "      <td>\\nChrome Version       : 3.0.195.10\\r\\nURLs (i...</td>\n",
              "      <td>Compat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Redraw issue/truncation with confirmation item...</td>\n",
              "      <td>\\nChromium 0.3.155.0 (Developer Build 3546)\\r\\...</td>\n",
              "      <td>Bug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Implement CanvasRenderingContext2D for access ...</td>\n",
              "      <td>\\nApplications that do background image proces...</td>\n",
              "      <td>Feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ath9k: panic in ath_tx_last_beacon + 0x29a</td>\n",
              "      <td>\\nToT (3.0 kernel) panic'd on resume.  Was ass...</td>\n",
              "      <td>Bug</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...     type\n",
              "0  Define a way to enforce performance constraint...  ...      Bug\n",
              "1       Websites that don't work with Chrome Browser  ...   Compat\n",
              "2  Redraw issue/truncation with confirmation item...  ...      Bug\n",
              "3  Implement CanvasRenderingContext2D for access ...  ...  Feature\n",
              "4         ath9k: panic in ath_tx_last_beacon + 0x29a  ...      Bug\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtUix8uvznPl",
        "outputId": "19aaeb6a-603d-4735-bc2a-a5b726aaaf7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "DATA_PATH2 = '/content/drive/My Drive/Colab Notebooks/linux_bugs_usage_ready.csv'\n",
        "data2 = pd.read_csv(DATA_PATH2, sep='\\t')\n",
        "data_top2 = data2.head()\n",
        "print(\"Linux Data\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>message</th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oops when using ide-cd with 2.5.45 and cdrecord</td>\n",
              "      <td>Please enter Exact Kernel version:2.5.45 Distr...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NUMA-Q hangs during TSC initialization on boot.</td>\n",
              "      <td>Exact Kernel version: 2.5.46 Distribution: deb...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "      <td>Exact Kernel version: 2.5.46-mm1 Distribution:...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dcache spirals out of control on 2.5.43-mm2</td>\n",
              "      <td>Exact Kernel version: 2.5.43-mm2 Distribution:...</td>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64GB highmem BUG()</td>\n",
              "      <td>Exact Kernel version: 2.5.40 Hardware Environm...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... component\n",
              "0    oops when using ide-cd with 2.5.45 and cdrecord  ...       IDE\n",
              "1    NUMA-Q hangs during TSC initialization on boot.  ...      i386\n",
              "2  Enabling shared pagetables causes KDE to wierd...  ...     Other\n",
              "3        Dcache spirals out of control on 2.5.43-mm2  ...     Other\n",
              "4                                 64GB highmem BUG()  ...     Other\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOMKgPhXy8NI",
        "outputId": "698a566a-6e90-482a-8532-858a8a0b6c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#merge title and message\n",
        "def merge_title_and_message(data, message_col_name='message'):\n",
        "  data['text'] = data['title'] + ' ' + data[message_col_name]\n",
        "  data = data.drop(['title'], axis=1)\n",
        "  data = data.drop([message_col_name], axis=1)\n",
        "  return data\n",
        "data1 = merge_title_and_message(data1, message_col_name='description')\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Merge Title and Message Data\")\n",
        "data_top1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Merge Title and Message Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Define a way to enforce performance constraint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>Websites that don't work with Chrome Browser \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Redraw issue/truncation with confirmation item...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>Implement CanvasRenderingContext2D for access ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k: panic in ath_tx_last_beacon + 0x29a \\nT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  Define a way to enforce performance constraint...\n",
              "1   Compat  Websites that don't work with Chrome Browser \\...\n",
              "2      Bug  Redraw issue/truncation with confirmation item...\n",
              "3  Feature  Implement CanvasRenderingContext2D for access ...\n",
              "4      Bug  ath9k: panic in ath_tx_last_beacon + 0x29a \\nT..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbcMekOw0Hkj",
        "outputId": "0b176e78-4f76-45c8-8402-16c3137775f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "data2 = merge_title_and_message(data2)\n",
        "data_top2 = data2.head()\n",
        "print(\"Linux Merge Title and Message Data\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Merge Title and Message Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using ide-cd with 2.5.45 and cdrecor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>NUMA-Q hangs during TSC initialization on boot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dcache spirals out of control on 2.5.43-mm2 Ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64GB highmem BUG() Exact Kernel version: 2.5.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using ide-cd with 2.5.45 and cdrecor...\n",
              "1    P2 normal  ...  NUMA-Q hangs during TSC initialization on boot...\n",
              "2    P2 normal  ...  Enabling shared pagetables causes KDE to wierd...\n",
              "3  P2 blocking  ...  Dcache spirals out of control on 2.5.43-mm2 Ex...\n",
              "4    P2 normal  ...  64GB highmem BUG() Exact Kernel version: 2.5.4...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knalSpfb0y_O"
      },
      "source": [
        "def strip_punctuations(data, column_name='text'):\n",
        "  '''\n",
        "  Strips punctuations from the end of each token.\n",
        "  This uses suggestion from https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x-using-translate\n",
        "  to accomplish this really fast.\n",
        "  '''\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  data['text'] = data['text'].map(lambda s : str(s).translate(translator))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78oErrxr0I-U",
        "outputId": "1c9ed427-8510-48af-e5d4-182b9d16b9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "data1 = strip_punctuations(data1)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium strip punctuations\")\n",
        "data_top1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium strip punctuations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Define a way to enforce performance constraint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>Websites that dont work with Chrome Browser nC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Redraw issuetruncation with confirmation item ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>Implement CanvasRenderingContext2D for access ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic in athtxlastbeacon  0x29a nToT 30 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  Define a way to enforce performance constraint...\n",
              "1   Compat  Websites that dont work with Chrome Browser nC...\n",
              "2      Bug  Redraw issuetruncation with confirmation item ...\n",
              "3  Feature  Implement CanvasRenderingContext2D for access ...\n",
              "4      Bug  ath9k panic in athtxlastbeacon  0x29a nToT 30 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYN3rEq91og3",
        "outputId": "4d55943e-4fdd-4e8b-df01-a3b653da1bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "data2 = strip_punctuations(data2)\n",
        "data_top2 = data2.head()\n",
        "print(\"Linux strip punctuations\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux strip punctuations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using idecd with 2545 and cdrecord P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>NUMAQ hangs during TSC initialization on boot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dcache spirals out of control on 2543mm2 Exact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64GB highmem BUG Exact Kernel version 2540 Har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using idecd with 2545 and cdrecord P...\n",
              "1    P2 normal  ...  NUMAQ hangs during TSC initialization on boot ...\n",
              "2    P2 normal  ...  Enabling shared pagetables causes KDE to wierd...\n",
              "3  P2 blocking  ...  Dcache spirals out of control on 2543mm2 Exact...\n",
              "4    P2 normal  ...  64GB highmem BUG Exact Kernel version 2540 Har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sm1_0af1wwD",
        "outputId": "32f25e7d-cb9a-4dec-fa61-b00401da3d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "def remove_linux_garbage(data):\n",
        "  '''\n",
        "  Linux data contains lots of garbage, e.g. memory addresses - 0000f800\n",
        "  '''\n",
        "  def is_garbage(w):\n",
        "    return len(w) >= 7 and sum(c.isdigit() for c in w) >= 2\n",
        "\n",
        "  data['text'] = data['text'].map(lambda s : ' '.join(map(lambda w: w if not is_garbage(w) else ' ', s.split())))\n",
        "  return data\n",
        "data = remove_linux_garbage(data2)\n",
        "data_top2 = data2.head()\n",
        "print(\"Remove linux garbage\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove linux garbage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using idecd with 2545 and cdrecord P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>NUMAQ hangs during TSC initialization on boot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dcache spirals out of control on   Exact Kerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64GB highmem BUG Exact Kernel version 2540 Har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using idecd with 2545 and cdrecord P...\n",
              "1    P2 normal  ...  NUMAQ hangs during TSC initialization on boot ...\n",
              "2    P2 normal  ...  Enabling shared pagetables causes KDE to wierd...\n",
              "3  P2 blocking  ...  Dcache spirals out of control on   Exact Kerne...\n",
              "4    P2 normal  ...  64GB highmem BUG Exact Kernel version 2540 Har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RKcfm_73vX",
        "outputId": "138e5e3d-67d2-49be-b7bc-d3f954fb188d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "def cast_to_lowercase(data):\n",
        "  data['text'] = data['text'].map(lambda s : s.lower())\n",
        "  return data\n",
        "data1 = cast_to_lowercase(data1)\n",
        "data2 = cast_to_lowercase(data2)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Lowercase\")\n",
        "data_top1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Lowercase\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>define a way to enforce performance constraint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>websites that dont work with chrome browser nc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>redraw issuetruncation with confirmation item ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>implement canvasrenderingcontext2d for access ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic in athtxlastbeacon  0x29a ntot 30 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  define a way to enforce performance constraint...\n",
              "1   Compat  websites that dont work with chrome browser nc...\n",
              "2      Bug  redraw issuetruncation with confirmation item ...\n",
              "3  Feature  implement canvasrenderingcontext2d for access ...\n",
              "4      Bug  ath9k panic in athtxlastbeacon  0x29a ntot 30 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S8-uCI592ld",
        "outputId": "b0f7ad9b-fd8e-4a9d-9426-28b881f7d3d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "data_top2 = data2.head()\n",
        "print(\"Linux Lowercase\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Lowercase\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using idecd with 2545 and cdrecord p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>numaq hangs during tsc initialization on boot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>enabling shared pagetables causes kde to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>dcache spirals out of control on   exact kerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64gb highmem bug exact kernel version 2540 har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using idecd with 2545 and cdrecord p...\n",
              "1    P2 normal  ...  numaq hangs during tsc initialization on boot ...\n",
              "2    P2 normal  ...  enabling shared pagetables causes kde to wierd...\n",
              "3  P2 blocking  ...  dcache spirals out of control on   exact kerne...\n",
              "4    P2 normal  ...  64gb highmem bug exact kernel version 2540 har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A2rDzOo75Go",
        "outputId": "0ed6bc33-2e49-43bc-f3b0-50068c6e22e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "def remove_stopwords(data):\n",
        "  stop_words = stopwords.words('english')\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  stop_words = set([w.translate(translator) for w in stop_words]) # Apostrophes were removed already\n",
        "\n",
        "  data['text'] = data['text'].map(lambda s : ' '.join(map(lambda w: w if w not in stop_words else ' ', s.split())))\n",
        "  return data\n",
        "data1 = remove_stopwords(data1)\n",
        "data2 = remove_stopwords(data2)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Stopword\")\n",
        "data_top1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Stopword\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>define   way   enforce performance constraint ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>websites     work   chrome browser nchrome ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>redraw issuetruncation   confirmation item   d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>implement canvasrenderingcontext2d   access   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic   athtxlastbeacon 0x29a ntot 30 ke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  define   way   enforce performance constraint ...\n",
              "1   Compat  websites     work   chrome browser nchrome ver...\n",
              "2      Bug  redraw issuetruncation   confirmation item   d...\n",
              "3  Feature  implement canvasrenderingcontext2d   access   ...\n",
              "4      Bug  ath9k panic   athtxlastbeacon 0x29a ntot 30 ke..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQd7GmvG9-Tu",
        "outputId": "c95e6ba9-2702-49a5-d6f1-65ea3a7e586b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "data_top2 = data2.head()\n",
        "print(\"Linux Stopword\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Stopword\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops   using idecd   2545   cdrecord please en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>numaq hangs   tsc initialization   boot exact ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>enabling shared pagetables causes kde   wierd ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>dcache spirals     control   exact kernel vers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64gb highmem bug exact kernel version 2540 har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops   using idecd   2545   cdrecord please en...\n",
              "1    P2 normal  ...  numaq hangs   tsc initialization   boot exact ...\n",
              "2    P2 normal  ...  enabling shared pagetables causes kde   wierd ...\n",
              "3  P2 blocking  ...  dcache spirals     control   exact kernel vers...\n",
              "4    P2 normal  ...  64gb highmem bug exact kernel version 2540 har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_-eFCVq77mJ",
        "outputId": "e87aa275-3fab-443f-e796-e7a51feb2af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "def remove_rare_words(data, min_count=3):\n",
        "  wc = {} # WordCount\n",
        "  def proc_word(s):\n",
        "    for w in set(s.split()):\n",
        "      if w in wc:\n",
        "        wc[w] += 1\n",
        "      else:\n",
        "        wc[w] = 1\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    proc_word(row['text'])\n",
        "\n",
        "  data['text'] = data['text'].map(lambda s : ' '.join(map(lambda w: w if wc[w] >= min_count else ' ', s.split())))\n",
        "  return data\n",
        "data1 = remove_rare_words(data1)\n",
        "data2 = remove_rare_words(data2)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium rare words\")\n",
        "data_top1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium rare words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>define way enforce performance constraint spec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>websites work chrome browser nchrome version  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>redraw   confirmation item download bar nchrom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>implement canvasrenderingcontext2d access work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic     ntot 30 kernel   resume associ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  define way enforce performance constraint spec...\n",
              "1   Compat  websites work chrome browser nchrome version  ...\n",
              "2      Bug  redraw   confirmation item download bar nchrom...\n",
              "3  Feature  implement canvasrenderingcontext2d access work...\n",
              "4      Bug  ath9k panic     ntot 30 kernel   resume associ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzD8ivdv-FtH",
        "outputId": "90d2df75-21d3-4e8d-fbe0-eb1ccf5ca680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "data_top2 = data2.head()\n",
        "print(\"Linux rare words\")\n",
        "data_top2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux rare words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops using idecd 2545 cdrecord please enter ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>numaq hangs tsc initialization boot exact kern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>enabling shared pagetables causes kde wierd ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>dcache   control exact kernel version distribu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64gb highmem bug exact kernel version 2540 har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops using idecd 2545 cdrecord please enter ex...\n",
              "1    P2 normal  ...  numaq hangs tsc initialization boot exact kern...\n",
              "2    P2 normal  ...  enabling shared pagetables causes kde wierd ex...\n",
              "3  P2 blocking  ...  dcache   control exact kernel version distribu...\n",
              "4    P2 normal  ...  64gb highmem bug exact kernel version 2540 har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1xsyuj9kFS-"
      },
      "source": [
        "translator = str.maketrans('', '', string.punctuation)\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words = set([w.translate(translator) for w in stop_words])\n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for dataset\n",
        "    Every dataset is lower cased except\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"\\\\\", \"\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "    string = re.sub(r\"\\\"\", \"\", string)\n",
        "    string = string.strip().lower().translate(translator)\n",
        "    return string\n",
        "def remove_stopwords_from_sent(sent):\n",
        "    res = []\n",
        "    for word in sent:\n",
        "        if word not in stop_words:\n",
        "            res.append(word)\n",
        "    return res\n",
        "def map_sentence(sent):\n",
        "    out = np.empty((max_sentence_len, embed_size_word2vec))\n",
        "    for ind, word in enumerate(sent):\n",
        "        if ind == max_sentence_len:\n",
        "            break\n",
        "        if word in vocabulary:\n",
        "            out[ind, :] = wordvec_model.wv[word]\n",
        "    return out\n",
        "def map_doc(doc):\n",
        "    out = np.empty((max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "    for ind, sent in enumerate(doc):\n",
        "        if ind == max_doc_len:\n",
        "            break\n",
        "        out[ind, :] = map_sentence(sent)\n",
        "    return out\n",
        "def build_sentences(X):\n",
        "    X_sentences = []\n",
        "    for doc in X:\n",
        "        sentences = sent_tokenize(doc)\n",
        "        cleaned = map(clean_str, sentences)\n",
        "        tokenized = map(word_tokenize, cleaned)\n",
        "        cleaned = map(remove_stopwords_from_sent, tokenized)\n",
        "        X_sentences.append(list(cleaned))\n",
        "    return X_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zg2x-05Uj58"
      },
      "source": [
        "#Attension Layer\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avUS-tYhi5A7"
      },
      "source": [
        "#RNN Class\n",
        "from __future__ import absolute_import\n",
        "import warnings\n",
        "from keras import backend as K\n",
        "from keras import activations\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.engine import Layer\n",
        "from keras.engine import InputSpec\n",
        "from keras.legacy import interfaces\n",
        "from keras.layers import RNN\n",
        "from keras.layers.recurrent import _generate_dropout_mask, _generate_dropout_ones\n",
        "\n",
        "class IndRNNCell(Layer):\n",
        "    \"\"\"Independently Recurrent Neural Networks Cell class.\n",
        "\n",
        "    Derived from the paper [Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN](https://arxiv.org/abs/1803.04831)\n",
        "    Ref: [Tensorflow implementation](https://github.com/batzner/indrnn)\n",
        "\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        recurrent_clip_min: Can be one of None, -1 or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, will calculate the clip value for `relu` activation\n",
        "        recurrent_clip_max: Can be one of None or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, will calculate the clip value for `relu` activation\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you pass None, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix, used for the linear transformation of the\n",
        "            recurrent state.\n",
        "            Can be `None` or an available initializer. Defaults to `None`.\n",
        "            If None, defaults to uniform initialization.\n",
        "            If None, and recurrent_clip_min/max is not None, then\n",
        "            it uses those clip values as for uniform initialization.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        implementation: Implementation mode, must be 2.\n",
        "            Mode 1 will structure its operations as a larger number of\n",
        "            smaller dot products and additions, whereas mode 2 will\n",
        "            batch them into fewer, larger operations. These modes will\n",
        "            have different performance profiles on different hardware and\n",
        "            for different applications.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units,\n",
        "                 recurrent_clip_min=-1,\n",
        "                 recurrent_clip_max=-1,\n",
        "                 activation='relu',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer=None,\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 implementation=2,\n",
        "                 **kwargs):\n",
        "        super(IndRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "        if implementation != 2:\n",
        "            warnings.warn(\n",
        "                \"IndRNN only supports implementation 2 for the moment. Defaulting to implementation = 2\")\n",
        "            implementation = 2\n",
        "\n",
        "        if recurrent_clip_min is None or recurrent_clip_max is None:\n",
        "            recurrent_clip_min = None\n",
        "            recurrent_clip_max = None\n",
        "\n",
        "        self.units = units\n",
        "        self.recurrent_clip_min = recurrent_clip_min\n",
        "        self.recurrent_clip_max = recurrent_clip_max\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer) \\\n",
        "                                     if recurrent_initializer is not None else None\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = min(1., max(0., dropout))\n",
        "        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
        "        self.implementation = implementation\n",
        "        self.state_size = (self.units,)\n",
        "        self._dropout_mask = None\n",
        "        self._recurrent_masks = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "\n",
        "        if self.recurrent_clip_min == -1 or self.recurrent_clip_max == -1:\n",
        "            self.recurrent_clip_min = 0.0\n",
        "\n",
        "            if hasattr(self, 'timesteps') and self.timesteps is not None:\n",
        "                self.recurrent_clip_max = pow(2.0, 1. / self.timesteps)\n",
        "            else:\n",
        "                warnings.warn(\"IndRNNCell: Number of timesteps could not be determined. \\n\"\n",
        "                              \"Defaulting to max clipping range of 1.0. \\n\"\n",
        "                              \"If this model was trained using a specific timestep during training, \"\n",
        "                              \"inference may be wrong due to this default setting.\\n\"\n",
        "                              \"Please ensure that you use the same number of timesteps during training \"\n",
        "                              \"and evaluation\")\n",
        "                self.recurrent_clip_max = 1.0\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                      name='input_kernel',\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.recurrent_initializer is None:\n",
        "            if self.recurrent_clip_min is not None and self.recurrent_clip_max is not None:\n",
        "                initialization_value = min(self.recurrent_clip_max, 1.0)\n",
        "                self.recurrent_initializer = initializers.uniform(-initialization_value,\n",
        "                                                                  initialization_value)\n",
        "            else:\n",
        "                self.recurrent_initializer = initializers.uniform(-1.0, 1.0)\n",
        "\n",
        "        self.recurrent_kernel = self.add_weight(shape=(self.units,),\n",
        "                                                name='recurrent_kernel',\n",
        "                                                initializer=self.recurrent_initializer,\n",
        "                                                regularizer=self.recurrent_regularizer,\n",
        "                                                constraint=self.recurrent_constraint)\n",
        "\n",
        "        if self.recurrent_clip_min is not None and self.recurrent_clip_max is not None:\n",
        "            if abs(self.recurrent_clip_min):\n",
        "                abs_recurrent_kernel = K.abs(self.recurrent_kernel)\n",
        "                min_recurrent_kernel = K.maximum(abs_recurrent_kernel, abs(self.recurrent_clip_min))\n",
        "                self.recurrent_kernel = K.sign(self.recurrent_kernel) * min_recurrent_kernel\n",
        "\n",
        "            self.recurrent_kernel = K.clip(self.recurrent_kernel,\n",
        "                                           self.recurrent_clip_min,\n",
        "                                           self.recurrent_clip_max)\n",
        "\n",
        "        if self.use_bias:\n",
        "            bias_initializer = self.bias_initializer\n",
        "\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        name='bias',\n",
        "                                        initializer=bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states, training=None):\n",
        "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
        "            self._dropout_mask = _generate_dropout_mask(\n",
        "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
        "                self.dropout,\n",
        "                training=training,\n",
        "                count=1)\n",
        "        if (0 < self.recurrent_dropout < 1 and\n",
        "                self._recurrent_masks is None):\n",
        "            _recurrent_mask = _generate_dropout_mask(\n",
        "                _generate_dropout_ones(inputs, self.units),\n",
        "                self.recurrent_dropout,\n",
        "                training=training,\n",
        "                count=1)\n",
        "            self._recurrent_masks = _recurrent_mask\n",
        "\n",
        "        # dropout matrices for input units\n",
        "        dp_mask = self._dropout_mask\n",
        "        # dropout matrices for recurrent units\n",
        "        rec_dp_masks = self._recurrent_masks\n",
        "\n",
        "        h_tm1 = states[0]  # previous state\n",
        "\n",
        "        if 0. < self.dropout < 1.:\n",
        "            inputs *= dp_mask[0]\n",
        "\n",
        "        if 0. < self.recurrent_dropout < 1.:\n",
        "            h_tm1 *= rec_dp_masks[0]\n",
        "\n",
        "        h = K.dot(inputs, self.kernel)\n",
        "        h = h + (h_tm1 * self.recurrent_kernel)\n",
        "\n",
        "        if self.use_bias:\n",
        "            h = K.bias_add(h, self.bias)\n",
        "\n",
        "        h = self.activation(h)\n",
        "\n",
        "        if 0 < self.dropout + self.recurrent_dropout:\n",
        "            if training is None:\n",
        "                h._uses_learning_phase = True\n",
        "        return h, [h]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'recurrent_clip_min': self.recurrent_clip_min,\n",
        "                  'recurrent_clip_max': self.recurrent_clip_max,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout,\n",
        "                  'implementation': self.implementation}\n",
        "        base_config = super(IndRNNCell, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class IndRNN(RNN):\n",
        "    \"\"\"Independently Recurrent Neural Networks Cell class.\n",
        "\n",
        "    Derived from the paper [Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN](https://arxiv.org/abs/1803.04831)\n",
        "    Ref: [Tensorflow implementation](https://github.com/batzner/indrnn)\n",
        "\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        recurrent_clip_min: Can be one of None, -1 or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, computes the default clipping range for Relu activations\n",
        "        recurrent_clip_max: Can be one of None, -1 or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, computes the default clipping range for Relu activations\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you pass None, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix,\n",
        "            used for the linear transformation of the recurrent state.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        unit_forget_bias: Boolean.\n",
        "            If True, add 1 to the bias of the forget gate at initialization.\n",
        "            Setting it to true will also force `bias_initializer=\"zeros\"`.\n",
        "            This is recommended in [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        implementation: Implementation mode, either 1 or 2.\n",
        "            Mode 1 will structure its operations as a larger number of\n",
        "            smaller dot products and additions, whereas mode 2 will\n",
        "            batch them into fewer, larger operations. These modes will\n",
        "            have different performance profiles on different hardware and\n",
        "            for different applications.\n",
        "        return_sequences: Boolean. Whether to return the last output.\n",
        "            in the output sequence, or the full sequence.\n",
        "        return_state: Boolean. Whether to return the last state\n",
        "            in addition to the output.\n",
        "        go_backwards: Boolean (default False).\n",
        "            If True, process the input sequence backwards and return the\n",
        "            reversed sequence.\n",
        "        stateful: Boolean (default False). If True, the last state\n",
        "            for each sample at index i in a batch will be used as initial\n",
        "            state for the sample of index i in the following batch.\n",
        "        unroll: Boolean (default False).\n",
        "            If True, the network will be unrolled,\n",
        "            else a symbolic loop will be used.\n",
        "            Unrolling can speed-up a RNN,\n",
        "            although it tends to be more memory-intensive.\n",
        "            Unrolling is only suitable for short sequences.\n",
        "\n",
        "    # References\n",
        "        - [Learning to forget: Continual prediction with NestedLSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n",
        "        - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n",
        "        - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n",
        "        - [Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN](https://arxiv.org/abs/1803.04831)\n",
        "    \"\"\"\n",
        "\n",
        "    @interfaces.legacy_recurrent_support\n",
        "    def __init__(self, units,\n",
        "                 recurrent_clip_min=-1,\n",
        "                 recurrent_clip_max=-1,\n",
        "                 activation='relu',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer=None,\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 implementation=2,\n",
        "                 return_sequences=False,\n",
        "                 return_state=False,\n",
        "                 go_backwards=False,\n",
        "                 stateful=False,\n",
        "                 unroll=False,\n",
        "                 **kwargs):\n",
        "        if implementation == 0:\n",
        "            warnings.warn('`implementation=0` has been deprecated, '\n",
        "                          'and now defaults to `implementation=2`.'\n",
        "                          'Please update your layer call.')\n",
        "        if K.backend() == 'theano':\n",
        "            warnings.warn(\n",
        "                'RNN dropout is no longer supported with the Theano backend '\n",
        "                'due to technical limitations. '\n",
        "                'You can either set `dropout` and `recurrent_dropout` to 0, '\n",
        "                'or use the TensorFlow backend.')\n",
        "            dropout = 0.\n",
        "            recurrent_dropout = 0.\n",
        "\n",
        "        cell = IndRNNCell(units,\n",
        "                          recurrent_clip_min=recurrent_clip_min,\n",
        "                          recurrent_clip_max=recurrent_clip_max,\n",
        "                          activation=activation,\n",
        "                          use_bias=use_bias,\n",
        "                          kernel_initializer=kernel_initializer,\n",
        "                          recurrent_initializer=recurrent_initializer,\n",
        "                          bias_initializer=bias_initializer,\n",
        "                          kernel_regularizer=kernel_regularizer,\n",
        "                          recurrent_regularizer=recurrent_regularizer,\n",
        "                          bias_regularizer=bias_regularizer,\n",
        "                          kernel_constraint=kernel_constraint,\n",
        "                          recurrent_constraint=recurrent_constraint,\n",
        "                          bias_constraint=bias_constraint,\n",
        "                          dropout=dropout,\n",
        "                          recurrent_dropout=recurrent_dropout,\n",
        "                          implementation=implementation)\n",
        "        super(IndRNN, self).__init__(cell,\n",
        "                                     return_sequences=return_sequences,\n",
        "                                     return_state=return_state,\n",
        "                                     go_backwards=go_backwards,\n",
        "                                     stateful=stateful,\n",
        "                                     unroll=unroll,\n",
        "                                     **kwargs)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        timesteps = input_shape[1]\n",
        "\n",
        "        if timesteps is None:\n",
        "            warnings.warn(\"Number of timesteps was not provided. If this model is being used for training purposes, \\n\"\n",
        "                          \"it is recommended to provide a finite number of timesteps when defining the input shape, \\n\"\n",
        "                          \"so as to initialize the weights of the recurrent kernel properly and avoid exploding gradients.\")\n",
        "\n",
        "        self.cell.timesteps = timesteps\n",
        "\n",
        "        super(IndRNN, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None, training=None, initial_state=None, constants=None):\n",
        "        self.cell._dropout_mask = None\n",
        "        self.cell._recurrent_masks = None\n",
        "        return super(IndRNN, self).call(inputs,\n",
        "                                        mask=mask,\n",
        "                                        training=training,\n",
        "                                        initial_state=initial_state,\n",
        "                                        constants=constants)\n",
        "\n",
        "    @property\n",
        "    def units(self):\n",
        "        return self.cell.units\n",
        "\n",
        "    @property\n",
        "    def recurrent_clip_min(self):\n",
        "        return self.cell.recurrent_clip_min\n",
        "\n",
        "    @property\n",
        "    def recurrent_clip_max(self):\n",
        "        return self.cell.recurrent_clip_max\n",
        "\n",
        "    @property\n",
        "    def activation(self):\n",
        "        return self.cell.activation\n",
        "\n",
        "    @property\n",
        "    def use_bias(self):\n",
        "        return self.cell.use_bias\n",
        "\n",
        "    @property\n",
        "    def kernel_initializer(self):\n",
        "        return self.cell.kernel_initializer\n",
        "\n",
        "    @property\n",
        "    def recurrent_initializer(self):\n",
        "        return self.cell.recurrent_initializer\n",
        "\n",
        "    @property\n",
        "    def bias_initializer(self):\n",
        "        return self.cell.bias_initializer\n",
        "\n",
        "    @property\n",
        "    def kernel_regularizer(self):\n",
        "        return self.cell.kernel_regularizer\n",
        "\n",
        "    @property\n",
        "    def recurrent_regularizer(self):\n",
        "        return self.cell.recurrent_regularizer\n",
        "\n",
        "    @property\n",
        "    def bias_regularizer(self):\n",
        "        return self.cell.bias_regularizer\n",
        "\n",
        "    @property\n",
        "    def kernel_constraint(self):\n",
        "        return self.cell.kernel_constraint\n",
        "\n",
        "    @property\n",
        "    def recurrent_constraint(self):\n",
        "        return self.cell.recurrent_constraint\n",
        "\n",
        "    @property\n",
        "    def bias_constraint(self):\n",
        "        return self.cell.bias_constraint\n",
        "\n",
        "    @property\n",
        "    def dropout(self):\n",
        "        return self.cell.dropout\n",
        "\n",
        "    @property\n",
        "    def recurrent_dropout(self):\n",
        "        return self.cell.recurrent_dropout\n",
        "\n",
        "    @property\n",
        "    def implementation(self):\n",
        "        return self.cell.implementation\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'recurrent_clip_min': self.recurrent_clip_min,\n",
        "                  'recurrent_clip_max': self.recurrent_clip_max,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout,\n",
        "                  'implementation': self.implementation}\n",
        "        base_config = super(IndRNN, self).get_config()\n",
        "        del base_config['cell']\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        if 'implementation' in config and config['implementation'] == 0:\n",
        "            config['implementation'] = 2\n",
        "        return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhd-QOZbkbs5"
      },
      "source": [
        "def make_model(rnn_dim=64, dense_dim=50):\n",
        "    def attention_block():\n",
        "        def f(input):\n",
        "            rnn2 = Bidirectional(IndRNN(rnn_dim, return_sequences=True))(input)\n",
        "            drop2 = Dropout(0.75)(rnn2)\n",
        "            dense = TimeDistributed(Dense(dense_dim))(drop2)\n",
        "            drop3 = Dropout(0.5)(dense)\n",
        "            att = AttentionWithContext()(drop3)\n",
        "            return att\n",
        "        return f\n",
        "    with K.name_scope('sentence_enc'):\n",
        "        sentence_input = Input(shape=(max_sentence_len, embed_size_word2vec))\n",
        "        word_att = attention_block()(sentence_input)\n",
        "        sentEncoder = Model(sentence_input, word_att)\n",
        "\n",
        "    with K.name_scope('doc_enc'):\n",
        "        doc_input = Input(shape=(max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "        sent_enc = TimeDistributed(sentEncoder)(doc_input)\n",
        "        doc_att = attention_block()(sent_enc)\n",
        "        preds = Dense(y_trans.shape[-1], activation='softmax')(doc_att)\n",
        "\n",
        "        model = Model(doc_input, preds)\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrKv1fIBhqsz",
        "outputId": "e88834c4-f148-405e-ceab-df951d536df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Linux Process\n",
        "def read_linux(feature):\n",
        "    return data2['text'], data2[feature]\n",
        "\n",
        "X, Y = read_linux('importance')\n",
        "X_sentences = build_sentences(X)\n",
        "list(map(print, X_sentences[2]))\n",
        "# Word2vec parameters\n",
        "min_word_frequency_word2vec = 3\n",
        "embed_size_word2vec = 200\n",
        "context_window_word2vec = 5\n",
        "X_merged = list(map(lambda l: list(chain(*l)), X_sentences))\n",
        "print(X_merged[13])\n",
        "wordvec_model = Word2Vec(X_merged, min_count=min_word_frequency_word2vec,\n",
        "                         size=embed_size_word2vec, window=context_window_word2vec)\n",
        "max_doc_len = 5\n",
        "max_sentence_len = 100\n",
        "num = len(X_sentences)\n",
        "vocabulary = wordvec_model.wv.vocab\n",
        "print(\"Vocabulary\", len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['enabling', 'shared', 'pagetables', 'causes', 'kde', 'wierd', 'exact', 'kernel', 'version', 'distribution', 'redhat', '72', '73', 'hardware', 'environment', 'p4', 'pc', 'software', 'environment', 'kde', 'problem', 'description', 'enabling', 'shared', 'pagetables', 'causes', 'kde', 'wierd', 'steps', 'reproduce', 'start', 'kde']\n",
            "['dri', 'unsupported', 'via', 'chipset', 'device', 'id', 'exact', 'kernel', 'version', 'kernel', 'command', 'line', 'ro', 'rootdevhdc1', 'agptryunsupported1', 'distribution', 'red', 'hat', 'rawhide', 'hardware', 'environment', 'gigabyte', 'ga', '7vax', 'httpwwwgigabytecomproducts7vaxhtm', 'northbridge', 'via', 'kt400', 'southbridge', 'via', '8235', 'latest', 'bios', 'mga', 'g400', 'boot', 'linux', 'agpgart', 'interface', 'v099', 'c', 'jeff', 'hartmann', 'agpgart', 'maximum', 'main', 'memory', 'use', 'agp', 'memory', '439m', 'agpgart', 'unsupported', 'via', 'chipset', 'device', 'id', 'might', 'want', 'try', 'agptryunsupported1', 'agpgart', 'supported', 'devices', 'found', 'drmdrminit', 'error', 'initialize', 'agpgart', 'module', 'uninitialised', 'timer', 'warning', 'computer', 'ok', 'call', 'trace']\n",
            "Vocabulary 34345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-s-Czkj7j4"
      },
      "source": [
        "x = np.memmap('filename1.myarray', dtype=np.float64, mode='w+',shape=(num, max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "for ind, doc in enumerate(X_sentences):\n",
        "    x[ind, :] = map_doc(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyn94hJwpJdY",
        "outputId": "3f0a2d50-6069-4471-b367-32e70e70aa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "RNN = CuDNNGRU\n",
        "enc = LabelEncoder()\n",
        "yc = enc.fit_transform(Y)\n",
        "oh = LabelBinarizer()\n",
        "y_trans = oh.fit_transform(yc)\n",
        "model = make_model(rnn_dim=64, dense_dim=64)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 5, 100, 200)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 5, 64)             38336     \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 5, 128)            8448      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 5, 64)             8256      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 5, 64)             0         \n",
            "_________________________________________________________________\n",
            "attention_with_context_6 (At (None, 64)                4224      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 9)                 585       \n",
            "=================================================================\n",
            "Total params: 59,849\n",
            "Trainable params: 59,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IydJmRLjInk",
        "outputId": "1c63581b-305d-43f7-9613-be2960a1ae06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "sz = len(y_trans)\n",
        "x_train = x[int(0.1 * sz):int(0.95 * sz)]\n",
        "x_test = np.concatenate((x[:int(0.1 * sz)], x[int(0.95 * sz):]))\n",
        "y_train = y_trans[int(0.1 * sz):int(0.95 * sz)]\n",
        "y_test = np.concatenate((y_trans[:int(0.1 * sz)], y_trans[int(0.95 * sz):]))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "          nb_epoch=13, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 13988 samples, validate on 2468 samples\n",
            "Epoch 1/10\n",
            "  272/13988 [..............................] - ETA: 7:46 - loss: nan - acc: 0.0110"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1008e0431576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m               metrics=['acc'])\n\u001b[1;32m      9\u001b[0m model.fit(x_train, y_train, validation_data=(x_test, y_test),\n\u001b[0;32m---> 10\u001b[0;31m           nb_epoch=10, batch_size=16)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1219\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmemmap\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_mmap'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DumwXW8mjNbJ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def report(x, y):\n",
        "    labels = np.argmax(y, axis=-1)\n",
        "    predicted = np.argmax(model.predict(x), axis=-1)\n",
        "    print(\"Accuracy Linux\", accuracy_score(labels, predicted))\n",
        "    print(\"F1-Linux\", f1_score(labels, predicted, average='weighted'))\n",
        "print(\"Training\")\n",
        "report(x_train, y_train)\n",
        "print(\"Testing\")\n",
        "report(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzoVRCTWiCXR",
        "outputId": "53191ab0-dc67-4315-b9e6-f01f8eef409c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#chrome Process\n",
        "def read_chrome():\n",
        "    data1['text'] = data1['text'].map(lambda s: str(s).replace('\\\\r', '').replace('\\\\n', '. '))\n",
        "    return data1['text'], data1['type']\n",
        "X, Y =read_chrome()\n",
        "X_sentences = build_sentences(X)\n",
        "list(map(print, X_sentences[2]))\n",
        "# Word2vec parameters\n",
        "min_word_frequency_word2vec = 3\n",
        "embed_size_word2vec = 200\n",
        "context_window_word2vec = 5\n",
        "X_merged = list(map(lambda l: list(chain(*l)), X_sentences))\n",
        "print(X_merged[13])\n",
        "wordvec_model = Word2Vec(X_merged, min_count=min_word_frequency_word2vec,\n",
        "                         size=embed_size_word2vec, window=context_window_word2vec)\n",
        "max_doc_len = 5\n",
        "max_sentence_len = 100\n",
        "num = len(X_sentences)\n",
        "vocabulary = wordvec_model.wv.vocab\n",
        "print(\"Vocabulary\", len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['redraw', 'confirmation', 'item', 'download', 'bar', 'nchromium', '031550', 'developer', 'build', 'steps', 'reproduce', 'download', 'exe', 'file', 'tab', 'use', 'urlrn2', 'resize', 'chrome', 'window', 'making', 'narrower', 'current', 'item', 'disappearsrn3', 'switch', 'another', 'tab', 'resize', 'window', 'widthrn4', 'switch', 'back', 'tab', 'downloadsrnrnwhat', 'expected', 'output', 'rnrnthe', 'download', 'confirmation', 'item', 'properly', 'redrawn', 'download', 'barrnrnwhat', 'see', 'insteadrnrnthe', 'download', 'confirmation', 'item', 'truncated', 'resized', 'triggers', 'redraw', 'item']\n",
            "['regression', 'aol', 'submit', 'button', 'aol', 'mail', 'registration', 'page', 'aligned', 'incorrectly', 'nchrome', 'version', '201690', 'official', 'build', '11238rnurls', 'applicable', 'browsers', 'testednadd', 'ok', 'fail', 'browsers', 'tested', 'issuen', 'firefox', '3', 'okrn', 'ie', '7', 'okrnrnwhat', 'steps', 'reproduce', 'problemn1', 'go', 'click', 'aol', 'mail', 'stuff', 'right', 'side', 'page', 'rn3', 'click', 'red', 'button', 'get', 'free', 'aol', 'scroll', 'end', 'registration', 'pagernrnwhat', 'expected', 'resultnsubmit', 'button', 'aligned', 'correctlyrnrnwhat', 'happens', 'button', 'overlapping', 'border', 'around', 'terms', 'service', 'issue', 'reproducible', '1015448', 'official', 'build', '9043', 'safari', 'reproducible', 'chrome', '201700', 'developer', 'build', 'safari', 'rn31', 'webkit', 'r41443']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twn0A_pvjwgd"
      },
      "source": [
        "x = np.memmap('filename1.myarray', dtype=np.float64, mode='w+',shape=(num, max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "for ind, doc in enumerate(X_sentences):\n",
        "    x[ind, :] = map_doc(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPPsxfXwklsQ"
      },
      "source": [
        "RNN = CuDNNGRU\n",
        "enc = LabelEncoder()\n",
        "yc = enc.fit_transform(Y)\n",
        "oh = LabelBinarizer()\n",
        "y_trans = oh.fit_transform(yc)\n",
        "model = make_model(rnn_dim=64, dense_dim=64)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD-bWqbVkmV-"
      },
      "source": [
        "sz = len(y_trans)\n",
        "x_train = x[int(0.1 * sz):int(0.95 * sz)]\n",
        "x_test = np.concatenate((x[:int(0.1 * sz)], x[int(0.95 * sz):]))\n",
        "y_train = y_trans[int(0.1 * sz):int(0.95 * sz)]\n",
        "y_test = np.concatenate((y_trans[:int(0.1 * sz)], y_trans[int(0.95 * sz):]))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "          nb_epoch=13, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr-0aMbCkqHo"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def report(x, y):\n",
        "    labels = np.argmax(y, axis=-1)\n",
        "    predicted = np.argmax(model.predict(x), axis=-1)\n",
        "    print(\"Accuracy Crome\", accuracy_score(labels, predicted))\n",
        "    print(\"F1-Crome\", f1_score(labels, predicted, average='weighted'))\n",
        "print(\"Training\")\n",
        "report(x_train, y_train)\n",
        "print(\"Testing\")\n",
        "report(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}