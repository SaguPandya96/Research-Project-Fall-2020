{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research Project Deep learning Code .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJPRxmjRkOKIQ5uH4/84+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaguPandya96/Research-Project-Fall-2020/blob/master/Research_Project_Deep_learning_Code_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kigwiiZevz40"
      },
      "source": [
        "# **Research Project DL Code**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl2X-Lh0vSYV"
      },
      "source": [
        "**1. Import the libraries And Data**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNYkHtZc0UdK",
        "outputId": "c2dc2e42-5ccc-4bc4-d2a0-d4e9ebfb2dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "from textblob.classifiers import NaiveBayesClassifier as NBC\n",
        "from textblob.classifiers import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import itertools\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43p4vhDj032n",
        "outputId": "a05b3481-b39f-4296-c950-8dcb4959c4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2TU9VquwGaa"
      },
      "source": [
        "**2. Import the Chromium Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhXfXPNT1CVp",
        "outputId": "85a845b3-b841-4d49-abf8-3bc91955cf04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "#load data\n",
        "DATA_PATH1 = '/content/drive/My Drive/Research Project/chromium.csv'\n",
        "data1 = pd.read_csv(DATA_PATH1, sep='\\t')\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Data\")\n",
        "data_top1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Define a way to enforce performance constraint...</td>\n",
              "      <td>\\nThere are cases where tests should fail if a...</td>\n",
              "      <td>Bug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Websites that don't work with Chrome Browser</td>\n",
              "      <td>\\nChrome Version       : 3.0.195.10\\r\\nURLs (i...</td>\n",
              "      <td>Compat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Redraw issue/truncation with confirmation item...</td>\n",
              "      <td>\\nChromium 0.3.155.0 (Developer Build 3546)\\r\\...</td>\n",
              "      <td>Bug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Implement CanvasRenderingContext2D for access ...</td>\n",
              "      <td>\\nApplications that do background image proces...</td>\n",
              "      <td>Feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ath9k: panic in ath_tx_last_beacon + 0x29a</td>\n",
              "      <td>\\nToT (3.0 kernel) panic'd on resume.  Was ass...</td>\n",
              "      <td>Bug</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...     type\n",
              "0  Define a way to enforce performance constraint...  ...      Bug\n",
              "1       Websites that don't work with Chrome Browser  ...   Compat\n",
              "2  Redraw issue/truncation with confirmation item...  ...      Bug\n",
              "3  Implement CanvasRenderingContext2D for access ...  ...  Feature\n",
              "4         ath9k: panic in ath_tx_last_beacon + 0x29a  ...      Bug\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0eUQjL9wVyM"
      },
      "source": [
        "**3. Import the Linux Bugs Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT0itQss1HA5",
        "outputId": "14d5080e-44de-444d-fd6f-7de43c7e9547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "DATA_PATH2 = '/content/drive/My Drive/Research Project/linux_bugs_usage_ready.csv'\n",
        "data2 = pd.read_csv(DATA_PATH2, sep='\\t')\n",
        "data_top2 = data2.head()\n",
        "print(\"Linux Data\")\n",
        "data_top2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>message</th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oops when using ide-cd with 2.5.45 and cdrecord</td>\n",
              "      <td>Please enter Exact Kernel version:2.5.45 Distr...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NUMA-Q hangs during TSC initialization on boot.</td>\n",
              "      <td>Exact Kernel version: 2.5.46 Distribution: deb...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "      <td>Exact Kernel version: 2.5.46-mm1 Distribution:...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dcache spirals out of control on 2.5.43-mm2</td>\n",
              "      <td>Exact Kernel version: 2.5.43-mm2 Distribution:...</td>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64GB highmem BUG()</td>\n",
              "      <td>Exact Kernel version: 2.5.40 Hardware Environm...</td>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... component\n",
              "0    oops when using ide-cd with 2.5.45 and cdrecord  ...       IDE\n",
              "1    NUMA-Q hangs during TSC initialization on boot.  ...      i386\n",
              "2  Enabling shared pagetables causes KDE to wierd...  ...     Other\n",
              "3        Dcache spirals out of control on 2.5.43-mm2  ...     Other\n",
              "4                                 64GB highmem BUG()  ...     Other\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njbSrdHNwlMO"
      },
      "source": [
        "**3. Merge title and message for chromium dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOMKgPhXy8NI",
        "outputId": "0c6d1354-5160-4abe-e5a3-3b990bb8a708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "\n",
        "def merge_title_and_message(data, message_col_name='message'):\n",
        "  data['text'] = data['title'] + ' ' + data[message_col_name]\n",
        "  data = data.drop(['title'], axis=1)\n",
        "  data = data.drop([message_col_name], axis=1)\n",
        "  return data\n",
        "data1 = merge_title_and_message(data1, message_col_name='description')\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Merge Title and Message Data\")\n",
        "data_top1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Merge Title and Message Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Define a way to enforce performance constraint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>Websites that don't work with Chrome Browser \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Redraw issue/truncation with confirmation item...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>Implement CanvasRenderingContext2D for access ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k: panic in ath_tx_last_beacon + 0x29a \\nT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  Define a way to enforce performance constraint...\n",
              "1   Compat  Websites that don't work with Chrome Browser \\...\n",
              "2      Bug  Redraw issue/truncation with confirmation item...\n",
              "3  Feature  Implement CanvasRenderingContext2D for access ...\n",
              "4      Bug  ath9k: panic in ath_tx_last_beacon + 0x29a \\nT..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPaCoL9kwxiK"
      },
      "source": [
        "**4. Merge title and message for Linux Bugs dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbcMekOw0Hkj",
        "outputId": "fd26d9ea-7d33-467b-9bb4-d25f2c1872fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "data2 = merge_title_and_message(data2)\n",
        "data_top2 = data2.head()\n",
        "print(\"Linux Merge Title and Message Data\")\n",
        "data_top2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Merge Title and Message Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using ide-cd with 2.5.45 and cdrecor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>NUMA-Q hangs during TSC initialization on boot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dcache spirals out of control on 2.5.43-mm2 Ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64GB highmem BUG() Exact Kernel version: 2.5.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using ide-cd with 2.5.45 and cdrecor...\n",
              "1    P2 normal  ...  NUMA-Q hangs during TSC initialization on boot...\n",
              "2    P2 normal  ...  Enabling shared pagetables causes KDE to wierd...\n",
              "3  P2 blocking  ...  Dcache spirals out of control on 2.5.43-mm2 Ex...\n",
              "4    P2 normal  ...  64GB highmem BUG() Exact Kernel version: 2.5.4...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mm863UWw9Bx"
      },
      "source": [
        "**5. Remove the Strip Punctuation For Both the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knalSpfb0y_O"
      },
      "source": [
        "def strip_punctuations(data, column_name='text'):\n",
        "  '''\n",
        "  Strips punctuations from the end of each token.\n",
        "  This uses suggestion from https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x-using-translate\n",
        "  to accomplish this really fast.\n",
        "  '''\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  data['text'] = data['text'].map(lambda s : str(s).translate(translator))\n",
        "  return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78oErrxr0I-U",
        "outputId": "1ae74100-b168-4fe1-9b85-8a2cae677fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "data1 = strip_punctuations(data1)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium strip punctuations\")\n",
        "data_top1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium strip punctuations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Define a way to enforce performance constraint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>Websites that dont work with Chrome Browser nC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Redraw issuetruncation with confirmation item ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>Implement CanvasRenderingContext2D for access ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic in athtxlastbeacon  0x29a nToT 30 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  Define a way to enforce performance constraint...\n",
              "1   Compat  Websites that dont work with Chrome Browser nC...\n",
              "2      Bug  Redraw issuetruncation with confirmation item ...\n",
              "3  Feature  Implement CanvasRenderingContext2D for access ...\n",
              "4      Bug  ath9k panic in athtxlastbeacon  0x29a nToT 30 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYN3rEq91og3",
        "outputId": "0c208c03-2d39-46b4-f5bc-420605a53079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "data2 = strip_punctuations(data2)\n",
        "data_top2 = data2.head()\n",
        "print(\"Linux strip punctuations\")\n",
        "data_top2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux strip punctuations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using idecd with 2545 and cdrecord P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>NUMAQ hangs during TSC initialization on boot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dcache spirals out of control on 2543mm2 Exact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64GB highmem BUG Exact Kernel version 2540 Har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using idecd with 2545 and cdrecord P...\n",
              "1    P2 normal  ...  NUMAQ hangs during TSC initialization on boot ...\n",
              "2    P2 normal  ...  Enabling shared pagetables causes KDE to wierd...\n",
              "3  P2 blocking  ...  Dcache spirals out of control on 2543mm2 Exact...\n",
              "4    P2 normal  ...  64GB highmem BUG Exact Kernel version 2540 Har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYna-0oqxRRU"
      },
      "source": [
        "**6. Remove the linux garbage in Linux Bugs data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sm1_0af1wwD",
        "outputId": "33f8f08d-5e6e-4144-fa40-a93f38656175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def remove_linux_garbage(data):\n",
        "  '''\n",
        "  Linux data contains lots of garbage, e.g. memory addresses - 0000f800\n",
        "  '''\n",
        "  def is_garbage(w):\n",
        "    return len(w) >= 7 and sum(c.isdigit() for c in w) >= 2\n",
        "\n",
        "  data['text'] = data['text'].map(lambda s : ' '.join(map(lambda w: w if not is_garbage(w) else ' ', s.split())))\n",
        "  return data\n",
        "data = remove_linux_garbage(data2)\n",
        "data_top2 = data2.head()\n",
        "print(\"Remove linux garbage\")\n",
        "data_top2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove linux garbage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using idecd with 2545 and cdrecord P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>NUMAQ hangs during TSC initialization on boot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>Enabling shared pagetables causes KDE to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dcache spirals out of control on   Exact Kerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64GB highmem BUG Exact Kernel version 2540 Har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using idecd with 2545 and cdrecord P...\n",
              "1    P2 normal  ...  NUMAQ hangs during TSC initialization on boot ...\n",
              "2    P2 normal  ...  Enabling shared pagetables causes KDE to wierd...\n",
              "3  P2 blocking  ...  Dcache spirals out of control on   Exact Kerne...\n",
              "4    P2 normal  ...  64GB highmem BUG Exact Kernel version 2540 Har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5leNcfOx9BA"
      },
      "source": [
        "**7. Convert string into lower case with the chromium dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RKcfm_73vX",
        "outputId": "2124fea5-6441-4853-d668-5bd47cfc4f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def cast_to_lowercase(data):\n",
        "  data['text'] = data['text'].map(lambda s : s.lower())\n",
        "  return data\n",
        "data1 = cast_to_lowercase(data1)\n",
        "data2 = cast_to_lowercase(data2)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Lowercase\")\n",
        "data_top1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Lowercase\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>define a way to enforce performance constraint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>websites that dont work with chrome browser nc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>redraw issuetruncation with confirmation item ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>implement canvasrenderingcontext2d for access ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic in athtxlastbeacon  0x29a ntot 30 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  define a way to enforce performance constraint...\n",
              "1   Compat  websites that dont work with chrome browser nc...\n",
              "2      Bug  redraw issuetruncation with confirmation item ...\n",
              "3  Feature  implement canvasrenderingcontext2d for access ...\n",
              "4      Bug  ath9k panic in athtxlastbeacon  0x29a ntot 30 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKgVFTVfyOo5"
      },
      "source": [
        "**8. Convert string into lower case with the Linux dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S8-uCI592ld",
        "outputId": "c954256c-ca09-4832-a5c0-8a3b8d662c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "data_top2 = data2.head()\n",
        "print(\"Linux Lowercase\")\n",
        "data_top2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Lowercase\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops when using idecd with 2545 and cdrecord p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>numaq hangs during tsc initialization on boot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>enabling shared pagetables causes kde to wierd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>dcache spirals out of control on   exact kerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64gb highmem bug exact kernel version 2540 har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops when using idecd with 2545 and cdrecord p...\n",
              "1    P2 normal  ...  numaq hangs during tsc initialization on boot ...\n",
              "2    P2 normal  ...  enabling shared pagetables causes kde to wierd...\n",
              "3  P2 blocking  ...  dcache spirals out of control on   exact kerne...\n",
              "4    P2 normal  ...  64gb highmem bug exact kernel version 2540 har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wXyNDfZyURN"
      },
      "source": [
        "**9. Remove the stopwords in Chromium dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A2rDzOo75Go",
        "outputId": "a311b023-5ee4-47e0-da7e-4cde0e1e100c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def remove_stopwords(data):\n",
        "  stop_words = stopwords.words('english')\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  stop_words = set([w.translate(translator) for w in stop_words]) # Apostrophes were removed already\n",
        "\n",
        "  data['text'] = data['text'].map(lambda s : ' '.join(map(lambda w: w if w not in stop_words else ' ', s.split())))\n",
        "  return data\n",
        "data1 = remove_stopwords(data1)\n",
        "data2 = remove_stopwords(data2)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium Stopword\")\n",
        "data_top1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium Stopword\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>define   way   enforce performance constraint ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>websites     work   chrome browser nchrome ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>redraw issuetruncation   confirmation item   d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>implement canvasrenderingcontext2d   access   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic   athtxlastbeacon 0x29a ntot 30 ke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  define   way   enforce performance constraint ...\n",
              "1   Compat  websites     work   chrome browser nchrome ver...\n",
              "2      Bug  redraw issuetruncation   confirmation item   d...\n",
              "3  Feature  implement canvasrenderingcontext2d   access   ...\n",
              "4      Bug  ath9k panic   athtxlastbeacon 0x29a ntot 30 ke..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZsjnc_9yjn5"
      },
      "source": [
        "**10. Remove the stopwords in Linux dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQd7GmvG9-Tu",
        "outputId": "8963f14a-18b5-49bb-b61d-6b4737e2b407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "data_top2 = data2.head()\n",
        "print(\"Linux Stopword\")\n",
        "data_top2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux Stopword\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops   using idecd   2545   cdrecord please en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>numaq hangs   tsc initialization   boot exact ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>enabling shared pagetables causes kde   wierd ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>dcache spirals     control   exact kernel vers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64gb highmem bug exact kernel version 2540 har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops   using idecd   2545   cdrecord please en...\n",
              "1    P2 normal  ...  numaq hangs   tsc initialization   boot exact ...\n",
              "2    P2 normal  ...  enabling shared pagetables causes kde   wierd ...\n",
              "3  P2 blocking  ...  dcache spirals     control   exact kernel vers...\n",
              "4    P2 normal  ...  64gb highmem bug exact kernel version 2540 har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwzO66CFypJT"
      },
      "source": [
        "**11. Remove the rare words in Chromium Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_-eFCVq77mJ",
        "outputId": "fbd93b21-f72e-4338-ada3-ac49ee44f86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def remove_rare_words(data, min_count=3):\n",
        "  wc = {} # WordCount\n",
        "  def proc_word(s):\n",
        "    for w in set(s.split()):\n",
        "      if w in wc:\n",
        "        wc[w] += 1\n",
        "      else:\n",
        "        wc[w] = 1\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    proc_word(row['text'])\n",
        "\n",
        "  data['text'] = data['text'].map(lambda s : ' '.join(map(lambda w: w if wc[w] >= min_count else ' ', s.split())))\n",
        "  return data\n",
        "data1 = remove_rare_words(data1)\n",
        "data2 = remove_rare_words(data2)\n",
        "data_top1 = data1.head()\n",
        "print(\"Chromium rare words\")\n",
        "data_top1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chromium rare words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bug</td>\n",
              "      <td>define way enforce performance constraint spec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Compat</td>\n",
              "      <td>websites work chrome browser nchrome version  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bug</td>\n",
              "      <td>redraw   confirmation item download bar nchrom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature</td>\n",
              "      <td>implement canvasrenderingcontext2d access work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bug</td>\n",
              "      <td>ath9k panic     ntot 30 kernel   resume associ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      Bug  define way enforce performance constraint spec...\n",
              "1   Compat  websites work chrome browser nchrome version  ...\n",
              "2      Bug  redraw   confirmation item download bar nchrom...\n",
              "3  Feature  implement canvasrenderingcontext2d access work...\n",
              "4      Bug  ath9k panic     ntot 30 kernel   resume associ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_dyOaa_y2xM"
      },
      "source": [
        "**12. Remove the rare words in Linux Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzD8ivdv-FtH",
        "outputId": "b787e8e8-e56c-4022-da38-26f7cac863fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "data_top2 = data2.head()\n",
        "print(\"Linux rare words\")\n",
        "data_top2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux rare words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>product</th>\n",
              "      <th>component</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>IDE</td>\n",
              "      <td>oops using idecd 2545 cdrecord please enter ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Platform Specific/Hardware</td>\n",
              "      <td>i386</td>\n",
              "      <td>numaq hangs tsc initialization boot exact kern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>enabling shared pagetables causes kde wierd ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P2 blocking</td>\n",
              "      <td>IO/Storage</td>\n",
              "      <td>Other</td>\n",
              "      <td>dcache   control exact kernel version distribu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P2 normal</td>\n",
              "      <td>Memory Management</td>\n",
              "      <td>Other</td>\n",
              "      <td>64gb highmem bug exact kernel version 2540 har...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    importance  ...                                               text\n",
              "0    P2 normal  ...  oops using idecd 2545 cdrecord please enter ex...\n",
              "1    P2 normal  ...  numaq hangs tsc initialization boot exact kern...\n",
              "2    P2 normal  ...  enabling shared pagetables causes kde wierd ex...\n",
              "3  P2 blocking  ...  dcache   control exact kernel version distribu...\n",
              "4    P2 normal  ...  64gb highmem bug exact kernel version 2540 har...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUfcsB8N3XTa"
      },
      "source": [
        "**13. Import the deep triage library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJSmX603TpM"
      },
      "source": [
        "# DeepTriage\n",
        "# This code is adapted from http://bugtriage.mybluemix.net/\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "from gensim.models import Word2Vec\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, LSTM, Input, merge, BatchNormalization, Bidirectional\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Word2vec parameters\n",
        "min_word_frequency_word2vec = 3\n",
        "embed_size_word2vec = 200\n",
        "context_window_word2vec = 5\n",
        "\n",
        "# Classifier hyperparameters\n",
        "max_sentence_len = 100 \n",
        "min_sentence_length = 2\n",
        "batch_size = 32"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAAYIxW3xSd"
      },
      "source": [
        "def bidir_rnn_classify(data):\n",
        "  '''\n",
        "  Use the approach suggested at http://bugtriage.mybluemix.net/ to do\n",
        "  classification.\n",
        "  '''\n",
        "  class_to_predict = 'importance' # component product importance\n",
        "  data = shuffle(data, random_state=77)\n",
        "\n",
        "  num_records = len(data)\n",
        "  data_train = data[:int(0.85 * num_records)]\n",
        "  data_test = data[int(0.85 * num_records):]\n",
        "\n",
        "  train_data = [x[0] for x in data_train[['text']].to_records(index=False)]\n",
        "  train_labels = [x[0] for x in data_train[[class_to_predict]].to_records(index=False)]\n",
        "  unique_train_label = list(set(train_labels))\n",
        "\n",
        "  test_data = [x[0] for x in data_test[['text']].to_records(index=False)]\n",
        "  test_labels = [x[0] for x in data_test[[class_to_predict]].to_records(index=False)]\n",
        "\n",
        "  # Tokenize data\n",
        "  train_data = [text.split() for text in train_data] # TODO(Vladimir) - try nltk tokenize here\n",
        "  test_data = [text.split() for text in test_data]\n",
        "  all_data = train_data + test_data\n",
        "\n",
        "  print('Data examples')\n",
        "  print(all_data[:5])\n",
        "\n",
        "  # Generate word2vec\n",
        "  wordvec_model = Word2Vec(all_data, min_count=min_word_frequency_word2vec,\n",
        "                           size=embed_size_word2vec, window=context_window_word2vec)\n",
        "  vocabulary = wordvec_model.wv.vocab\n",
        "  vocab_size = len(vocabulary)\n",
        "\n",
        "  print('Vocab size is ' + str(vocab_size))\n",
        "\n",
        "  X_train = np.empty(shape=[len(train_data), max_sentence_len, embed_size_word2vec],\n",
        "                     dtype='float32')\n",
        "  Y_train = np.empty(shape=[len(train_labels), 1], dtype='int32')\n",
        "  # 1 - start of sentence, # 2 - end of sentence, # 0 - zero padding. Hence, word indices start with 3\n",
        "  print('Building X_train!')\n",
        "  for j, curr_row in enumerate(train_data):\n",
        "    if j % 100 == 0:\n",
        "      print('Building X_train j = ' + str(j))\n",
        "    sequence_cnt = 0\n",
        "    for item in curr_row:\n",
        "      if item in vocabulary:\n",
        "        X_train[j, sequence_cnt, :] = wordvec_model[item]\n",
        "        sequence_cnt = sequence_cnt + 1\n",
        "        if sequence_cnt == max_sentence_len - 1:\n",
        "          break\n",
        "    for k in range(sequence_cnt, max_sentence_len):\n",
        "      X_train[j, k, :] = np.zeros((1, embed_size_word2vec))\n",
        "    Y_train[j, 0] = unique_train_label.index(train_labels[j])\n",
        "\n",
        "  X_test = np.empty(shape=[len(test_data), max_sentence_len, embed_size_word2vec],\n",
        "                    dtype='float32')\n",
        "  Y_test = np.empty(shape=[len(test_labels), 1], dtype='int32')\n",
        "  # 1 - start of sentence, # 2 - end of sentence, # 0 - zero padding. Hence, word indices start with 3\n",
        "  print('Building X_test!')\n",
        "  for j, curr_row in enumerate(test_data):\n",
        "    if j % 100 == 0:\n",
        "      print('Building X_test j = ' + str(j))\n",
        "    sequence_cnt = 0\n",
        "    for item in curr_row:\n",
        "      if item in vocabulary:\n",
        "        X_test[j, sequence_cnt, :] = wordvec_model[item]\n",
        "        sequence_cnt = sequence_cnt + 1\n",
        "        if sequence_cnt == max_sentence_len - 1:\n",
        "          break\n",
        "    for k in range(sequence_cnt, max_sentence_len):\n",
        "      X_test[j, k, :] = np.zeros((1, embed_size_word2vec))\n",
        "    Y_test[j, 0] = unique_train_label.index(test_labels[j])\n",
        "\n",
        "  y_train = np_utils.to_categorical(Y_train, len(unique_train_label))\n",
        "\n",
        "  print('Bulding KERAS models!') \n",
        "#import from keras library \n",
        "  sequence = Input(shape=(max_sentence_len, embed_size_word2vec), dtype='float32')\n",
        "  lstm = Bidirectional(LSTM(1024))(sequence)\n",
        "  after_dp = Dropout(0.5)(lstm)\n",
        "  output = Dense(len(unique_train_label), activation='softmax')(after_dp)\n",
        "  model = Model(sequence, output)\n",
        "  rms = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  print('Training the model!')\n",
        "  hist = model.fit(X_train, y_train,batch_size=batch_size, epochs=5)\n",
        "\n",
        "  train_result = hist.history\n",
        "  print(train_result)\n",
        "\n",
        "  train_prediction = model.predict(X_train)\n",
        "\n",
        "  total_train_correct = 0\n",
        "  for j, ll in enumerate(train_prediction):\n",
        "    if np.argmax(ll) == Y_train[j]:\n",
        "      total_train_correct += 1\n",
        "\n",
        "  print('Train accuracy:', total_train_correct * 1.0 / len(train_prediction))\n",
        "\n",
        "  test_prediction = model.predict(X_test)\n",
        "\n",
        "  total_test_correct = 0\n",
        "  labels = []\n",
        "  predicted = []\n",
        "  for j, ll in enumerate(test_prediction):\n",
        "    predicted.append(np.argmax(ll))\n",
        "    labels.append(Y_test[j])\n",
        "    if np.argmax(ll) == Y_test[j]:\n",
        "      total_test_correct += 1\n",
        "\n",
        "  print('Test accuracy:', total_test_correct * 1.0 / len(test_prediction))\n",
        "  print('Test F1:', f1_score(labels, predicted, average='weighted'))\n",
        "\n",
        "  return total_test_correct * 1.0 / len(test_prediction)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYi6h9OB30eQ",
        "outputId": "ae71e93b-013b-4413-ff4b-a081609eefe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bidir_rnn_classify(data2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data examples\n",
            "[['battery', 'charging', 'state', 'change', 'discharging', 'distribution', 'debian', 'unstable', 'hardware', 'environment', 'fujitsu', 'laptop', 'software', 'environment', 'commandline', 'problem', 'description', 'ac', 'power', 'removed', 'reattached', 'update', 'expected', 'charging', 'state', 'listed', 'discharging', 'despite', 'fact', 'laptop', 'plugged', 'strangely', 'enough', 'procacpiacadapteracstate', 'update', 'properly', 'problem', 'also', 'mentioned', 'someone', 'else', 'mailing', 'list', 'steps', 'reproduce', 'cat', 'procacpiacadapteracstate', 'state', 'online', 'cat', 'present', 'yes', 'capacity', 'state', 'ok', 'charging', 'state', 'discharging', 'present', 'rate', '0', 'remaining', 'capacity', '4360', 'mah', 'present', 'voltage', 'mv'], ['merlin', 'pcmcia', 'card', 'recognized', 'serial', 'port', 'recent', 'kernel', 'bug', 'occur', '24x', 'distribution', 'debian', 'hardware', 'environment', 'ibm', 'laptop', 't42', 'software', 'environment', 'kernelorg', 'kernel', 'problem', 'description', 'insert', 'pcmcia', 'card', 'log', 'detects', 'serial', 'port', 'noticed', 'steps', 'reproduce', 'insert', 'card', 'merlin', 'pcmcia', 'novatel', 'vodafone', 'fcc', 'id', 'syslog', 'feb', '7', 'localhost', 'kernel', 'pccard', 'pcmcia', 'card', 'inserted', 'slot', '0', 'write', 'see', 'need', 'install', 'pcmciautils', 'pcmcia', 'utilities', 'linux', '26', 'reading', 'mentions', 'module', 'pcmcia', '16', 'bit', 'cards', 'loaded', 'automaticaly', 'modprobe', 'everything', 'starts', 'working', 'please', 'close', 'call', 'hope', 'helps', 'someone', 'else', 'feb', '8', 'localhost', 'kernel', 'pcmcia', 'registering', 'new', 'device', 'feb', '8', 'localhost', 'kernel', 'pcmcia', 'registering', 'new', 'device', 'feb', '8', 'localhost', 'kernel', '00', 'ttys1', 'io', '0x4100', 'irq', '3', '16550a'], ['kernel', 'bug', 'tun', 'device', 'closed', 'oops', 'attached', 'distribution', 'heavily', 'modified', 'redhat', '73', 'hardware', 'environment', 'msi', 'motherboard', 'athlon', 'thunderbird', '1ghz', 'cpu', '2', 'disks', 'etc', 'software', 'environment', 'problem', 'description', 'works', 'fine', 'normally', 'client', 'mode', 'system', 'server', 'end', 'link', 'shutdown', 'client', 'tried', 'close', 'open', 'tun', 'device', 'action', 'caused', 'oops', 'kernel', 'bug', 'invalid', 'operand', '0000', 'cpu', '0', 'eip', 'tainted', 'eflags', 'eip', 'eax', 'ebx', 'ecx', 'edx', 'esi', 'edi', 'ebp', 'esp', 'ds', '007b', 'es', '007b', 'ss', '0068', 'process', 'pid', '757', 'stack', 'call', 'trace', 'code', '0f', '0b', '0a', '01', 'a4', '6b', '36', 'c0', 'ff', '06', '83', '4e', '04', '08', '85', 'f6', '0f', '84', '01', '01'], ['dm', 'raid1', 'bug', 'subject', 'added', 'mm', 'tree', 'submitter', 'heiko', 'carstens', 'heikocarstensdeibmcom', 'date', '1645', 'references', 'handledby', 'alasdair', 'g', 'kergon', 'agkredhatcom', 'entry', 'used', 'tracking', 'regression', '2624', 'please', 'close', 'problem', 'fixed', 'mainline'], ['network', 'interface', 'detection', 'problem', 'nforce', '44x', 'mobos', 'recent', 'kernel', 'bug', 'occur', 'distribution', 'debian', '4', 'etch', 'testing', 'version', 'amd64', 'hardware', 'environment', 'motherboard', 'asus', 'k8n4e', 'deluxe', 'processor', 'amd', 'athlontm', '64', 'processor', '3200', '2200', 'mhz', 'bios', 'version', 'phoenix', 'bios', 'id', 'oem', 'asus', 'k8n4e', 'deluxe', 'acpi', 'bios', 'revision', '1010', 'chipset', 'nvidia', '44x', 'superio', 'ite', 'rev', '7', 'found', 'port', 'ethernet', 'controller', '1', 'gigabit', 'lan', 'phy', 'built', 'mobo', 'ethernet', 'controller', '2', 'dlink', '530', 'tx', '10100', 'ethernet', 'controller', 'memory', 'installed', '1024', 'mb', 'memory', 'maximum', '3072', 'mb', 'memory', 'slot', '01', '512', 'mb', 'memory', 'slot', '02', '512', 'mb', 'memory', 'slot', '03', '0', 'mb', 'acpi', 'revision', '10', 'software', 'environment', 'debian', 'linux', 'netinst', 'version', 'installation', 'image', 'found', 'installation', 'image', 'kernel', 'debian', '26179', 'waldidebianorg', 'gcc', 'version', '412', 'debian', '41113', '1', 'smp', 'wed', 'sep', '13', 'cest', '2006', 'x8664', 'unknown', 'problem', 'description', 'kernel', 'cant', 'detect', 'ethernet', 'controllers', 'despite', 'fact', 'two', 'ethernet', 'controllers', 'installed', 'system', 'builtin', 'controller', 'detected', 'dlink', 'controller', 'installed', 'attempt', 'resolve', 'problem', 'provide', 'solution', 'result', 'error', 'messages', 'identical', 'ones', 'produced', 'built', 'ethernet', 'adapter', 'error', 'message', 'ethernet', 'card', 'detected', 'order', 'replicate', 'problem', 'perform', 'following', 'steps', '1', 'attempt', 'installation', 'debian', 'linux', 'specified', 'hardware', '2', 'use', 'installation', 'image', 'specified', 'previously', 'message', '3', 'installation', 'step', 'identify', 'network', 'hardware', 'error', 'message', 'appear', 'problem', 'consistent', 'least', '10', 'installation', 'attempts', 'attempts', 'done', 'install', 'linux', 'specified', 'hardware', 'july', 'august', 'september', 'half', 'october', 'result', 'install', 'images', 'problems', 'lot', 'worse', 'older', 'install', 'images', 'attempt', 'made', 'remove', 'unnecessary', 'modules', 'command', 'modprobe', 'rf', 'modprobe', 'l', 'still', 'indicate', 'modprobe', 'installed', 'interpret', 'indication', 'modprobe', 'work', 'correctly', 'system', 'interpretation', 'wrong', 'need', 'information', 'modprobe', 'additional', 'information', 'static', 'ip', 'adress', 'used', 'dhcp', 'issue', 'ifconfig', 'report', 'loopback', 'interface', 'lspci', 'vvv', 'grep', 'produces', 'following', 'report', '000a0', 'bridge', 'corporation', 'ck804', 'ethernet', 'controller', 'rev', '2', '05070', 'ethernet', 'controller', 'technologies', 'inc', 'vt6105', 'rhine', 'iii', 'rev', '86', 'manually', 'selecting', 'forcedeth', 'driver', 'viarhine', 'driver', 'resolve', 'problem', 'resolved', 'starting', 'shell', 'issuing', 'commands', 'modprobe', 'f', 'forcedeth', 'modprobe', 'f', 'viarhine', 'combination', 'flags', 'tested', 'best', 'regards']]\n",
            "Vocab size is 34349\n",
            "Building X_train!\n",
            "Building X_train j = 0\n",
            "Building X_train j = 100\n",
            "Building X_train j = 200\n",
            "Building X_train j = 300\n",
            "Building X_train j = 400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building X_train j = 500\n",
            "Building X_train j = 600\n",
            "Building X_train j = 700\n",
            "Building X_train j = 800\n",
            "Building X_train j = 900\n",
            "Building X_train j = 1000\n",
            "Building X_train j = 1100\n",
            "Building X_train j = 1200\n",
            "Building X_train j = 1300\n",
            "Building X_train j = 1400\n",
            "Building X_train j = 1500\n",
            "Building X_train j = 1600\n",
            "Building X_train j = 1700\n",
            "Building X_train j = 1800\n",
            "Building X_train j = 1900\n",
            "Building X_train j = 2000\n",
            "Building X_train j = 2100\n",
            "Building X_train j = 2200\n",
            "Building X_train j = 2300\n",
            "Building X_train j = 2400\n",
            "Building X_train j = 2500\n",
            "Building X_train j = 2600\n",
            "Building X_train j = 2700\n",
            "Building X_train j = 2800\n",
            "Building X_train j = 2900\n",
            "Building X_train j = 3000\n",
            "Building X_train j = 3100\n",
            "Building X_train j = 3200\n",
            "Building X_train j = 3300\n",
            "Building X_train j = 3400\n",
            "Building X_train j = 3500\n",
            "Building X_train j = 3600\n",
            "Building X_train j = 3700\n",
            "Building X_train j = 3800\n",
            "Building X_train j = 3900\n",
            "Building X_train j = 4000\n",
            "Building X_train j = 4100\n",
            "Building X_train j = 4200\n",
            "Building X_train j = 4300\n",
            "Building X_train j = 4400\n",
            "Building X_train j = 4500\n",
            "Building X_train j = 4600\n",
            "Building X_train j = 4700\n",
            "Building X_train j = 4800\n",
            "Building X_train j = 4900\n",
            "Building X_train j = 5000\n",
            "Building X_train j = 5100\n",
            "Building X_train j = 5200\n",
            "Building X_train j = 5300\n",
            "Building X_train j = 5400\n",
            "Building X_train j = 5500\n",
            "Building X_train j = 5600\n",
            "Building X_train j = 5700\n",
            "Building X_train j = 5800\n",
            "Building X_train j = 5900\n",
            "Building X_train j = 6000\n",
            "Building X_train j = 6100\n",
            "Building X_train j = 6200\n",
            "Building X_train j = 6300\n",
            "Building X_train j = 6400\n",
            "Building X_train j = 6500\n",
            "Building X_train j = 6600\n",
            "Building X_train j = 6700\n",
            "Building X_train j = 6800\n",
            "Building X_train j = 6900\n",
            "Building X_train j = 7000\n",
            "Building X_train j = 7100\n",
            "Building X_train j = 7200\n",
            "Building X_train j = 7300\n",
            "Building X_train j = 7400\n",
            "Building X_train j = 7500\n",
            "Building X_train j = 7600\n",
            "Building X_train j = 7700\n",
            "Building X_train j = 7800\n",
            "Building X_train j = 7900\n",
            "Building X_train j = 8000\n",
            "Building X_train j = 8100\n",
            "Building X_train j = 8200\n",
            "Building X_train j = 8300\n",
            "Building X_train j = 8400\n",
            "Building X_train j = 8500\n",
            "Building X_train j = 8600\n",
            "Building X_train j = 8700\n",
            "Building X_train j = 8800\n",
            "Building X_train j = 8900\n",
            "Building X_train j = 9000\n",
            "Building X_train j = 9100\n",
            "Building X_train j = 9200\n",
            "Building X_train j = 9300\n",
            "Building X_train j = 9400\n",
            "Building X_train j = 9500\n",
            "Building X_train j = 9600\n",
            "Building X_train j = 9700\n",
            "Building X_train j = 9800\n",
            "Building X_train j = 9900\n",
            "Building X_train j = 10000\n",
            "Building X_train j = 10100\n",
            "Building X_train j = 10200\n",
            "Building X_train j = 10300\n",
            "Building X_train j = 10400\n",
            "Building X_train j = 10500\n",
            "Building X_train j = 10600\n",
            "Building X_train j = 10700\n",
            "Building X_train j = 10800\n",
            "Building X_train j = 10900\n",
            "Building X_train j = 11000\n",
            "Building X_train j = 11100\n",
            "Building X_train j = 11200\n",
            "Building X_train j = 11300\n",
            "Building X_train j = 11400\n",
            "Building X_train j = 11500\n",
            "Building X_train j = 11600\n",
            "Building X_train j = 11700\n",
            "Building X_train j = 11800\n",
            "Building X_train j = 11900\n",
            "Building X_train j = 12000\n",
            "Building X_train j = 12100\n",
            "Building X_train j = 12200\n",
            "Building X_train j = 12300\n",
            "Building X_train j = 12400\n",
            "Building X_train j = 12500\n",
            "Building X_train j = 12600\n",
            "Building X_train j = 12700\n",
            "Building X_train j = 12800\n",
            "Building X_train j = 12900\n",
            "Building X_train j = 13000\n",
            "Building X_train j = 13100\n",
            "Building X_train j = 13200\n",
            "Building X_train j = 13300\n",
            "Building X_train j = 13400\n",
            "Building X_train j = 13500\n",
            "Building X_train j = 13600\n",
            "Building X_train j = 13700\n",
            "Building X_train j = 13800\n",
            "Building X_train j = 13900\n",
            "Building X_test!\n",
            "Building X_test j = 0\n",
            "Building X_test j = 100\n",
            "Building X_test j = 200\n",
            "Building X_test j = 300\n",
            "Building X_test j = 400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building X_test j = 500\n",
            "Building X_test j = 600\n",
            "Building X_test j = 700\n",
            "Building X_test j = 800\n",
            "Building X_test j = 900\n",
            "Building X_test j = 1000\n",
            "Building X_test j = 1100\n",
            "Building X_test j = 1200\n",
            "Building X_test j = 1300\n",
            "Building X_test j = 1400\n",
            "Building X_test j = 1500\n",
            "Building X_test j = 1600\n",
            "Building X_test j = 1700\n",
            "Building X_test j = 1800\n",
            "Building X_test j = 1900\n",
            "Building X_test j = 2000\n",
            "Building X_test j = 2100\n",
            "Building X_test j = 2200\n",
            "Building X_test j = 2300\n",
            "Building X_test j = 2400\n",
            "Bulding KERAS models!\n",
            "Training the model!\n",
            "Epoch 1/5\n",
            "438/438 [==============================] - 4446s 10s/step - loss: 1.3021 - accuracy: 0.5767\n",
            "Epoch 2/5\n",
            "438/438 [==============================] - 4143s 9s/step - loss: 1.1484 - accuracy: 0.6136\n",
            "Epoch 3/5\n",
            "438/438 [==============================] - 4448s 10s/step - loss: 1.0898 - accuracy: 0.6253\n",
            "Epoch 4/5\n",
            "438/438 [==============================] - 4411s 10s/step - loss: 1.0173 - accuracy: 0.6428\n",
            "Epoch 5/5\n",
            "438/438 [==============================] - 4349s 10s/step - loss: 0.9232 - accuracy: 0.6688\n",
            "{'loss': [1.3021433353424072, 1.1483981609344482, 1.0898019075393677, 1.0173107385635376, 0.9232205152511597], 'accuracy': [0.5766783356666565, 0.6135697364807129, 0.6252949237823486, 0.6428111791610718, 0.6687638759613037]}\n",
            "Train accuracy: 0.7215271323371703\n",
            "Test accuracy: 0.6034831915755366\n",
            "Test F1: 0.5492236224527683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6034831915755366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCWywNvn4Rfw"
      },
      "source": [
        "#chromium Data\n",
        "def bidir_rnn_classify(data):\n",
        "  '''\n",
        "  Use the approach suggested at http://bugtriage.mybluemix.net/ to do\n",
        "  classification.\n",
        "  '''\n",
        "  class_to_predict = 'type' # component product importance\n",
        "  data = shuffle(data, random_state=77)\n",
        "\n",
        "  num_records = len(data)\n",
        "  data_train = data[:int(0.85 * num_records)]\n",
        "  data_test = data[int(0.85 * num_records):]\n",
        "\n",
        "  train_data = [x[0] for x in data_train[['text']].to_records(index=False)]\n",
        "  train_labels = [x[0] for x in data_train[[class_to_predict]].to_records(index=False)]\n",
        "  unique_train_label = list(set(train_labels))\n",
        "\n",
        "  test_data = [x[0] for x in data_test[['text']].to_records(index=False)]\n",
        "  test_labels = [x[0] for x in data_test[[class_to_predict]].to_records(index=False)]\n",
        "\n",
        "  # Tokenize data\n",
        "  train_data = [text.split() for text in train_data] # TODO(Vladimir) - try nltk tokenize here\n",
        "  test_data = [text.split() for text in test_data]\n",
        "  all_data = train_data + test_data\n",
        "\n",
        "  print('Data examples')\n",
        "  print(all_data[:5])\n",
        "\n",
        "  # Generate word2vec\n",
        "  wordvec_model = Word2Vec(all_data, min_count=min_word_frequency_word2vec,\n",
        "                           size=embed_size_word2vec, window=context_window_word2vec)\n",
        "  vocabulary = wordvec_model.wv.vocab\n",
        "  vocab_size = len(vocabulary)\n",
        "\n",
        "  print('Vocab size is ' + str(vocab_size))\n",
        "\n",
        "  X_train = np.empty(shape=[len(train_data), max_sentence_len, embed_size_word2vec],\n",
        "                     dtype='float32')\n",
        "  Y_train = np.empty(shape=[len(train_labels), 1], dtype='int32')\n",
        "  # 1 - start of sentence, # 2 - end of sentence, # 0 - zero padding. Hence, word indices start with 3\n",
        "  print('Building X_train!')\n",
        "  for j, curr_row in enumerate(train_data):\n",
        "    if j % 100 == 0:\n",
        "      print('Building X_train j = ' + str(j))\n",
        "    sequence_cnt = 0\n",
        "    for item in curr_row:\n",
        "      if item in vocabulary:\n",
        "        X_train[j, sequence_cnt, :] = wordvec_model[item]\n",
        "        sequence_cnt = sequence_cnt + 1\n",
        "        if sequence_cnt == max_sentence_len - 1:\n",
        "          break\n",
        "    for k in range(sequence_cnt, max_sentence_len):\n",
        "      X_train[j, k, :] = np.zeros((1, embed_size_word2vec))\n",
        "    Y_train[j, 0] = unique_train_label.index(train_labels[j])\n",
        "\n",
        "  X_test = np.empty(shape=[len(test_data), max_sentence_len, embed_size_word2vec],\n",
        "                    dtype='float32')\n",
        "  Y_test = np.empty(shape=[len(test_labels), 1], dtype='int32')\n",
        "  # 1 - start of sentence, # 2 - end of sentence, # 0 - zero padding. Hence, word indices start with 3\n",
        "  print('Building X_test!')\n",
        "  for j, curr_row in enumerate(test_data):\n",
        "    if j % 100 == 0:\n",
        "      print('Building X_test j = ' + str(j))\n",
        "    sequence_cnt = 0\n",
        "    for item in curr_row:\n",
        "      if item in vocabulary:\n",
        "        X_test[j, sequence_cnt, :] = wordvec_model[item]\n",
        "        sequence_cnt = sequence_cnt + 1\n",
        "        if sequence_cnt == max_sentence_len - 1:\n",
        "          break\n",
        "    for k in range(sequence_cnt, max_sentence_len):\n",
        "      X_test[j, k, :] = np.zeros((1, embed_size_word2vec))\n",
        "    Y_test[j, 0] = unique_train_label.index(test_labels[j])\n",
        "\n",
        "  y_train = np_utils.to_categorical(Y_train, len(unique_train_label))\n",
        "  print('Bulding KERAS models!')\n",
        "\n",
        "  sequence = Input(shape=(max_sentence_len, embed_size_word2vec), dtype='float32')\n",
        "  lstm = Bidirectional(LSTM(1024))(sequence)\n",
        "  after_dp = Dropout(0.5)(lstm)\n",
        "  output = Dense(len(unique_train_label), activation='softmax')(after_dp)\n",
        "  model = Model(sequence, output)\n",
        "  rms = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  print('Training the model!')\n",
        "  hist = model.fit(X_train, y_train,batch_size=batch_size, epochs=5)\n",
        "\n",
        "  train_result = hist.history\n",
        "  print(train_result)\n",
        "\n",
        "  train_prediction = model.predict(X_train)\n",
        "\n",
        "  total_train_correct = 0\n",
        "  for j, ll in enumerate(train_prediction):\n",
        "    if np.argmax(ll) == Y_train[j]:\n",
        "      total_train_correct += 1\n",
        "\n",
        "  print('Train accuracy:', total_train_correct * 1.0 / len(train_prediction))\n",
        "\n",
        "  test_prediction = model.predict(X_test)\n",
        "\n",
        "  total_test_correct = 0\n",
        "  labels = []\n",
        "  predicted = []\n",
        "  for j, ll in enumerate(test_prediction):\n",
        "    predicted.append(np.argmax(ll))\n",
        "    labels.append(Y_test[j])\n",
        "    if np.argmax(ll) == Y_test[j]:\n",
        "      total_test_correct += 1\n",
        "\n",
        "  print('Test accuracy:', total_test_correct * 1.0 / len(test_prediction))\n",
        "  print('Test F1:', f1_score(labels, predicted, average='weighted'))\n",
        "\n",
        "  return total_test_correct * 1.0 / len(test_prediction)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RglB14mh4gUt",
        "outputId": "ba8d1e23-018e-4ae9-b003-da8a79468291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bidir_rnn_classify(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data examples\n",
            "[['cannot', 'upload', 'photos', 'facebook', 'nchrome', 'version', '9059719rnurl', 'httpwwwfacebookcomrnbehavior', 'safari', '4x5xnbehavior', 'firefox', '3x4xnrnwhat', 'steps', 'reproduce', 'problemn1', 'using', 'chrome', 'upload', 'facebook', 'long', 'wait', 'one', 'upload', 'done', 'difference', 'create', 'new', 'album', 'add', 'new', 'photos', 'existing', 'try', 'firefox', 'browser', 'action', 'uploading', 'photos', 'facebook', 'bug', 'uploading', 'process', 'done', 'meet', 'problem', 'using', 'previous', 'chrome', 'version', 'week', 'situation'], ['legacy', 'webaudio', 'remove', 'nthis', 'tracking', 'bug', 'issues', 'legacy', 'webaudio', 'methods', 'attributes', 'need', 'removed', 'support', 'prefixed', 'audiocontext', 'removedn'], ['gn', 'need', 'mechanism', 'share', 'parts', 'gn', 'config', 'nv8', 'rolls', 'srcbuild', 'dependency', 'gn', 'time', 'eg', 'somebody', 'adds', 'something', 'build', 'requires', 'whitelist', 'v8s', 'gn', 'run', 'breaks', 'whitelisting', 'added', 'chromiums', 'gn', 'v8s', 'instead', 'sharing', 'would', 'even', 'better', 'whitelist', 'files', 'build', 'thirdparty', 'deps', 'v8', 'pov', 'wildcard', 'files', 'change', 'chromium', 'side', 'whitelisting', 'gn', 'existed', 'already'], ['crashes', 'google', 'chrome', '705362', 'dev', 'nchrome', 'version', '705362', 'devrnurls', 'applicable', 'browsers', 'testednadd', 'ok', 'fail', 'browsers', 'tested', 'issuensafari', '4n', 'firefox', '3x', 'okrnie', '7nie', '8nrnwhat', 'steps', 'reproduce', 'problemn1', 'go', 'expected', 'resultn', 'browser', 'crashesrnrnwhat', 'happens', 'insteadnrnrnplease', 'provide', 'additional', 'information', 'attach', 'screenshot', 'ifnpossiblenn'], ['value', 'gobi', 'nogobi', 'images', 'nthe', 'x86alex', 'builds', 'contain', 'hardware', 'board', 'value', 'value', 'prevent', 'us', 'differentiating', 'images', 'via', 'monitoring', 'update', 'n']]\n",
            "Vocab size is 50383\n",
            "Building X_train!\n",
            "Building X_train j = 0\n",
            "Building X_train j = 100\n",
            "Building X_train j = 200\n",
            "Building X_train j = 300\n",
            "Building X_train j = 400\n",
            "Building X_train j = 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building X_train j = 600\n",
            "Building X_train j = 700\n",
            "Building X_train j = 800\n",
            "Building X_train j = 900\n",
            "Building X_train j = 1000\n",
            "Building X_train j = 1100\n",
            "Building X_train j = 1200\n",
            "Building X_train j = 1300\n",
            "Building X_train j = 1400\n",
            "Building X_train j = 1500\n",
            "Building X_train j = 1600\n",
            "Building X_train j = 1700\n",
            "Building X_train j = 1800\n",
            "Building X_train j = 1900\n",
            "Building X_train j = 2000\n",
            "Building X_train j = 2100\n",
            "Building X_train j = 2200\n",
            "Building X_train j = 2300\n",
            "Building X_train j = 2400\n",
            "Building X_train j = 2500\n",
            "Building X_train j = 2600\n",
            "Building X_train j = 2700\n",
            "Building X_train j = 2800\n",
            "Building X_train j = 2900\n",
            "Building X_train j = 3000\n",
            "Building X_train j = 3100\n",
            "Building X_train j = 3200\n",
            "Building X_train j = 3300\n",
            "Building X_train j = 3400\n",
            "Building X_train j = 3500\n",
            "Building X_train j = 3600\n",
            "Building X_train j = 3700\n",
            "Building X_train j = 3800\n",
            "Building X_train j = 3900\n",
            "Building X_train j = 4000\n",
            "Building X_train j = 4100\n",
            "Building X_train j = 4200\n",
            "Building X_train j = 4300\n",
            "Building X_train j = 4400\n",
            "Building X_train j = 4500\n",
            "Building X_train j = 4600\n",
            "Building X_train j = 4700\n",
            "Building X_train j = 4800\n",
            "Building X_train j = 4900\n",
            "Building X_train j = 5000\n",
            "Building X_train j = 5100\n",
            "Building X_train j = 5200\n",
            "Building X_train j = 5300\n",
            "Building X_train j = 5400\n",
            "Building X_train j = 5500\n",
            "Building X_train j = 5600\n",
            "Building X_train j = 5700\n",
            "Building X_train j = 5800\n",
            "Building X_train j = 5900\n",
            "Building X_train j = 6000\n",
            "Building X_train j = 6100\n",
            "Building X_train j = 6200\n",
            "Building X_train j = 6300\n",
            "Building X_train j = 6400\n",
            "Building X_train j = 6500\n",
            "Building X_train j = 6600\n",
            "Building X_train j = 6700\n",
            "Building X_train j = 6800\n",
            "Building X_train j = 6900\n",
            "Building X_train j = 7000\n",
            "Building X_train j = 7100\n",
            "Building X_train j = 7200\n",
            "Building X_train j = 7300\n",
            "Building X_train j = 7400\n",
            "Building X_train j = 7500\n",
            "Building X_train j = 7600\n",
            "Building X_train j = 7700\n",
            "Building X_train j = 7800\n",
            "Building X_train j = 7900\n",
            "Building X_train j = 8000\n",
            "Building X_train j = 8100\n",
            "Building X_train j = 8200\n",
            "Building X_train j = 8300\n",
            "Building X_train j = 8400\n",
            "Building X_train j = 8500\n",
            "Building X_train j = 8600\n",
            "Building X_train j = 8700\n",
            "Building X_train j = 8800\n",
            "Building X_train j = 8900\n",
            "Building X_train j = 9000\n",
            "Building X_train j = 9100\n",
            "Building X_train j = 9200\n",
            "Building X_train j = 9300\n",
            "Building X_train j = 9400\n",
            "Building X_train j = 9500\n",
            "Building X_train j = 9600\n",
            "Building X_train j = 9700\n",
            "Building X_train j = 9800\n",
            "Building X_train j = 9900\n",
            "Building X_train j = 10000\n",
            "Building X_train j = 10100\n",
            "Building X_train j = 10200\n",
            "Building X_train j = 10300\n",
            "Building X_train j = 10400\n",
            "Building X_train j = 10500\n",
            "Building X_train j = 10600\n",
            "Building X_train j = 10700\n",
            "Building X_train j = 10800\n",
            "Building X_train j = 10900\n",
            "Building X_train j = 11000\n",
            "Building X_train j = 11100\n",
            "Building X_train j = 11200\n",
            "Building X_train j = 11300\n",
            "Building X_train j = 11400\n",
            "Building X_train j = 11500\n",
            "Building X_train j = 11600\n",
            "Building X_train j = 11700\n",
            "Building X_train j = 11800\n",
            "Building X_train j = 11900\n",
            "Building X_train j = 12000\n",
            "Building X_train j = 12100\n",
            "Building X_train j = 12200\n",
            "Building X_train j = 12300\n",
            "Building X_train j = 12400\n",
            "Building X_train j = 12500\n",
            "Building X_train j = 12600\n",
            "Building X_train j = 12700\n",
            "Building X_train j = 12800\n",
            "Building X_train j = 12900\n",
            "Building X_train j = 13000\n",
            "Building X_train j = 13100\n",
            "Building X_train j = 13200\n",
            "Building X_train j = 13300\n",
            "Building X_train j = 13400\n",
            "Building X_train j = 13500\n",
            "Building X_train j = 13600\n",
            "Building X_train j = 13700\n",
            "Building X_train j = 13800\n",
            "Building X_train j = 13900\n",
            "Building X_train j = 14000\n",
            "Building X_train j = 14100\n",
            "Building X_train j = 14200\n",
            "Building X_train j = 14300\n",
            "Building X_train j = 14400\n",
            "Building X_train j = 14500\n",
            "Building X_train j = 14600\n",
            "Building X_train j = 14700\n",
            "Building X_train j = 14800\n",
            "Building X_train j = 14900\n",
            "Building X_train j = 15000\n",
            "Building X_train j = 15100\n",
            "Building X_train j = 15200\n",
            "Building X_train j = 15300\n",
            "Building X_train j = 15400\n",
            "Building X_train j = 15500\n",
            "Building X_train j = 15600\n",
            "Building X_train j = 15700\n",
            "Building X_train j = 15800\n",
            "Building X_train j = 15900\n",
            "Building X_train j = 16000\n",
            "Building X_train j = 16100\n",
            "Building X_train j = 16200\n",
            "Building X_train j = 16300\n",
            "Building X_train j = 16400\n",
            "Building X_train j = 16500\n",
            "Building X_train j = 16600\n",
            "Building X_train j = 16700\n",
            "Building X_train j = 16800\n",
            "Building X_train j = 16900\n",
            "Building X_train j = 17000\n",
            "Building X_train j = 17100\n",
            "Building X_train j = 17200\n",
            "Building X_train j = 17300\n",
            "Building X_train j = 17400\n",
            "Building X_train j = 17500\n",
            "Building X_train j = 17600\n",
            "Building X_train j = 17700\n",
            "Building X_train j = 17800\n",
            "Building X_train j = 17900\n",
            "Building X_train j = 18000\n",
            "Building X_train j = 18100\n",
            "Building X_train j = 18200\n",
            "Building X_train j = 18300\n",
            "Building X_train j = 18400\n",
            "Building X_train j = 18500\n",
            "Building X_train j = 18600\n",
            "Building X_train j = 18700\n",
            "Building X_train j = 18800\n",
            "Building X_train j = 18900\n",
            "Building X_train j = 19000\n",
            "Building X_train j = 19100\n",
            "Building X_train j = 19200\n",
            "Building X_train j = 19300\n",
            "Building X_train j = 19400\n",
            "Building X_train j = 19500\n",
            "Building X_train j = 19600\n",
            "Building X_train j = 19700\n",
            "Building X_train j = 19800\n",
            "Building X_train j = 19900\n",
            "Building X_train j = 20000\n",
            "Building X_train j = 20100\n",
            "Building X_train j = 20200\n",
            "Building X_train j = 20300\n",
            "Building X_train j = 20400\n",
            "Building X_train j = 20500\n",
            "Building X_train j = 20600\n",
            "Building X_train j = 20700\n",
            "Building X_train j = 20800\n",
            "Building X_train j = 20900\n",
            "Building X_train j = 21000\n",
            "Building X_train j = 21100\n",
            "Building X_train j = 21200\n",
            "Building X_train j = 21300\n",
            "Building X_train j = 21400\n",
            "Building X_train j = 21500\n",
            "Building X_train j = 21600\n",
            "Building X_train j = 21700\n",
            "Building X_train j = 21800\n",
            "Building X_train j = 21900\n",
            "Building X_train j = 22000\n",
            "Building X_train j = 22100\n",
            "Building X_train j = 22200\n",
            "Building X_train j = 22300\n",
            "Building X_train j = 22400\n",
            "Building X_train j = 22500\n",
            "Building X_train j = 22600\n",
            "Building X_train j = 22700\n",
            "Building X_train j = 22800\n",
            "Building X_train j = 22900\n",
            "Building X_train j = 23000\n",
            "Building X_train j = 23100\n",
            "Building X_train j = 23200\n",
            "Building X_train j = 23300\n",
            "Building X_train j = 23400\n",
            "Building X_train j = 23500\n",
            "Building X_train j = 23600\n",
            "Building X_train j = 23700\n",
            "Building X_train j = 23800\n",
            "Building X_train j = 23900\n",
            "Building X_train j = 24000\n",
            "Building X_train j = 24100\n",
            "Building X_train j = 24200\n",
            "Building X_train j = 24300\n",
            "Building X_train j = 24400\n",
            "Building X_train j = 24500\n",
            "Building X_train j = 24600\n",
            "Building X_train j = 24700\n",
            "Building X_train j = 24800\n",
            "Building X_train j = 24900\n",
            "Building X_train j = 25000\n",
            "Building X_train j = 25100\n",
            "Building X_train j = 25200\n",
            "Building X_train j = 25300\n",
            "Building X_train j = 25400\n",
            "Building X_train j = 25500\n",
            "Building X_train j = 25600\n",
            "Building X_train j = 25700\n",
            "Building X_train j = 25800\n",
            "Building X_train j = 25900\n",
            "Building X_train j = 26000\n",
            "Building X_train j = 26100\n",
            "Building X_train j = 26200\n",
            "Building X_train j = 26300\n",
            "Building X_train j = 26400\n",
            "Building X_train j = 26500\n",
            "Building X_train j = 26600\n",
            "Building X_train j = 26700\n",
            "Building X_train j = 26800\n",
            "Building X_train j = 26900\n",
            "Building X_train j = 27000\n",
            "Building X_train j = 27100\n",
            "Building X_train j = 27200\n",
            "Building X_train j = 27300\n",
            "Building X_train j = 27400\n",
            "Building X_train j = 27500\n",
            "Building X_train j = 27600\n",
            "Building X_train j = 27700\n",
            "Building X_train j = 27800\n",
            "Building X_train j = 27900\n",
            "Building X_train j = 28000\n",
            "Building X_train j = 28100\n",
            "Building X_train j = 28200\n",
            "Building X_train j = 28300\n",
            "Building X_train j = 28400\n",
            "Building X_train j = 28500\n",
            "Building X_train j = 28600\n",
            "Building X_train j = 28700\n",
            "Building X_train j = 28800\n",
            "Building X_train j = 28900\n",
            "Building X_train j = 29000\n",
            "Building X_train j = 29100\n",
            "Building X_train j = 29200\n",
            "Building X_train j = 29300\n",
            "Building X_train j = 29400\n",
            "Building X_train j = 29500\n",
            "Building X_train j = 29600\n",
            "Building X_train j = 29700\n",
            "Building X_train j = 29800\n",
            "Building X_train j = 29900\n",
            "Building X_train j = 30000\n",
            "Building X_train j = 30100\n",
            "Building X_train j = 30200\n",
            "Building X_train j = 30300\n",
            "Building X_train j = 30400\n",
            "Building X_train j = 30500\n",
            "Building X_train j = 30600\n",
            "Building X_train j = 30700\n",
            "Building X_train j = 30800\n",
            "Building X_train j = 30900\n",
            "Building X_train j = 31000\n",
            "Building X_train j = 31100\n",
            "Building X_train j = 31200\n",
            "Building X_train j = 31300\n",
            "Building X_train j = 31400\n",
            "Building X_train j = 31500\n",
            "Building X_train j = 31600\n",
            "Building X_train j = 31700\n",
            "Building X_train j = 31800\n",
            "Building X_train j = 31900\n",
            "Building X_train j = 32000\n",
            "Building X_train j = 32100\n",
            "Building X_train j = 32200\n",
            "Building X_train j = 32300\n",
            "Building X_train j = 32400\n",
            "Building X_train j = 32500\n",
            "Building X_train j = 32600\n",
            "Building X_train j = 32700\n",
            "Building X_train j = 32800\n",
            "Building X_train j = 32900\n",
            "Building X_train j = 33000\n",
            "Building X_train j = 33100\n",
            "Building X_train j = 33200\n",
            "Building X_train j = 33300\n",
            "Building X_train j = 33400\n",
            "Building X_train j = 33500\n",
            "Building X_train j = 33600\n",
            "Building X_train j = 33700\n",
            "Building X_train j = 33800\n",
            "Building X_train j = 33900\n",
            "Building X_train j = 34000\n",
            "Building X_train j = 34100\n",
            "Building X_train j = 34200\n",
            "Building X_train j = 34300\n",
            "Building X_train j = 34400\n",
            "Building X_train j = 34500\n",
            "Building X_train j = 34600\n",
            "Building X_train j = 34700\n",
            "Building X_train j = 34800\n",
            "Building X_train j = 34900\n",
            "Building X_train j = 35000\n",
            "Building X_train j = 35100\n",
            "Building X_train j = 35200\n",
            "Building X_train j = 35300\n",
            "Building X_train j = 35400\n",
            "Building X_train j = 35500\n",
            "Building X_train j = 35600\n",
            "Building X_train j = 35700\n",
            "Building X_train j = 35800\n",
            "Building X_train j = 35900\n",
            "Building X_train j = 36000\n",
            "Building X_train j = 36100\n",
            "Building X_train j = 36200\n",
            "Building X_train j = 36300\n",
            "Building X_train j = 36400\n",
            "Building X_train j = 36500\n",
            "Building X_train j = 36600\n",
            "Building X_train j = 36700\n",
            "Building X_train j = 36800\n",
            "Building X_train j = 36900\n",
            "Building X_train j = 37000\n",
            "Building X_train j = 37100\n",
            "Building X_train j = 37200\n",
            "Building X_train j = 37300\n",
            "Building X_train j = 37400\n",
            "Building X_train j = 37500\n",
            "Building X_train j = 37600\n",
            "Building X_train j = 37700\n",
            "Building X_train j = 37800\n",
            "Building X_train j = 37900\n",
            "Building X_train j = 38000\n",
            "Building X_train j = 38100\n",
            "Building X_train j = 38200\n",
            "Building X_train j = 38300\n",
            "Building X_train j = 38400\n",
            "Building X_train j = 38500\n",
            "Building X_train j = 38600\n",
            "Building X_train j = 38700\n",
            "Building X_train j = 38800\n",
            "Building X_train j = 38900\n",
            "Building X_train j = 39000\n",
            "Building X_train j = 39100\n",
            "Building X_train j = 39200\n",
            "Building X_train j = 39300\n",
            "Building X_train j = 39400\n",
            "Building X_train j = 39500\n",
            "Building X_train j = 39600\n",
            "Building X_train j = 39700\n",
            "Building X_train j = 39800\n",
            "Building X_train j = 39900\n",
            "Building X_train j = 40000\n",
            "Building X_train j = 40100\n",
            "Building X_train j = 40200\n",
            "Building X_train j = 40300\n",
            "Building X_train j = 40400\n",
            "Building X_train j = 40500\n",
            "Building X_train j = 40600\n",
            "Building X_train j = 40700\n",
            "Building X_train j = 40800\n",
            "Building X_train j = 40900\n",
            "Building X_train j = 41000\n",
            "Building X_train j = 41100\n",
            "Building X_train j = 41200\n",
            "Building X_train j = 41300\n",
            "Building X_train j = 41400\n",
            "Building X_train j = 41500\n",
            "Building X_train j = 41600\n",
            "Building X_train j = 41700\n",
            "Building X_train j = 41800\n",
            "Building X_train j = 41900\n",
            "Building X_train j = 42000\n",
            "Building X_train j = 42100\n",
            "Building X_train j = 42200\n",
            "Building X_train j = 42300\n",
            "Building X_train j = 42400\n",
            "Building X_train j = 42500\n",
            "Building X_train j = 42600\n",
            "Building X_train j = 42700\n",
            "Building X_train j = 42800\n",
            "Building X_train j = 42900\n",
            "Building X_train j = 43000\n",
            "Building X_train j = 43100\n",
            "Building X_train j = 43200\n",
            "Building X_train j = 43300\n",
            "Building X_train j = 43400\n",
            "Building X_train j = 43500\n",
            "Building X_train j = 43600\n",
            "Building X_train j = 43700\n",
            "Building X_train j = 43800\n",
            "Building X_train j = 43900\n",
            "Building X_train j = 44000\n",
            "Building X_train j = 44100\n",
            "Building X_train j = 44200\n",
            "Building X_train j = 44300\n",
            "Building X_train j = 44400\n",
            "Building X_train j = 44500\n",
            "Building X_train j = 44600\n",
            "Building X_train j = 44700\n",
            "Building X_train j = 44800\n",
            "Building X_train j = 44900\n",
            "Building X_train j = 45000\n",
            "Building X_train j = 45100\n",
            "Building X_train j = 45200\n",
            "Building X_train j = 45300\n",
            "Building X_train j = 45400\n",
            "Building X_train j = 45500\n",
            "Building X_train j = 45600\n",
            "Building X_train j = 45700\n",
            "Building X_train j = 45800\n",
            "Building X_train j = 45900\n",
            "Building X_train j = 46000\n",
            "Building X_train j = 46100\n",
            "Building X_train j = 46200\n",
            "Building X_train j = 46300\n",
            "Building X_train j = 46400\n",
            "Building X_train j = 46500\n",
            "Building X_train j = 46600\n",
            "Building X_train j = 46700\n",
            "Building X_train j = 46800\n",
            "Building X_train j = 46900\n",
            "Building X_train j = 47000\n",
            "Building X_train j = 47100\n",
            "Building X_train j = 47200\n",
            "Building X_train j = 47300\n",
            "Building X_train j = 47400\n",
            "Building X_train j = 47500\n",
            "Building X_train j = 47600\n",
            "Building X_train j = 47700\n",
            "Building X_train j = 47800\n",
            "Building X_train j = 47900\n",
            "Building X_train j = 48000\n",
            "Building X_train j = 48100\n",
            "Building X_train j = 48200\n",
            "Building X_train j = 48300\n",
            "Building X_train j = 48400\n",
            "Building X_train j = 48500\n",
            "Building X_train j = 48600\n",
            "Building X_train j = 48700\n",
            "Building X_train j = 48800\n",
            "Building X_train j = 48900\n",
            "Building X_train j = 49000\n",
            "Building X_train j = 49100\n",
            "Building X_train j = 49200\n",
            "Building X_train j = 49300\n",
            "Building X_train j = 49400\n",
            "Building X_train j = 49500\n",
            "Building X_train j = 49600\n",
            "Building X_train j = 49700\n",
            "Building X_train j = 49800\n",
            "Building X_train j = 49900\n",
            "Building X_train j = 50000\n",
            "Building X_test!\n",
            "Building X_test j = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building X_test j = 100\n",
            "Building X_test j = 200\n",
            "Building X_test j = 300\n",
            "Building X_test j = 400\n",
            "Building X_test j = 500\n",
            "Building X_test j = 600\n",
            "Building X_test j = 700\n",
            "Building X_test j = 800\n",
            "Building X_test j = 900\n",
            "Building X_test j = 1000\n",
            "Building X_test j = 1100\n",
            "Building X_test j = 1200\n",
            "Building X_test j = 1300\n",
            "Building X_test j = 1400\n",
            "Building X_test j = 1500\n",
            "Building X_test j = 1600\n",
            "Building X_test j = 1700\n",
            "Building X_test j = 1800\n",
            "Building X_test j = 1900\n",
            "Building X_test j = 2000\n",
            "Building X_test j = 2100\n",
            "Building X_test j = 2200\n",
            "Building X_test j = 2300\n",
            "Building X_test j = 2400\n",
            "Building X_test j = 2500\n",
            "Building X_test j = 2600\n",
            "Building X_test j = 2700\n",
            "Building X_test j = 2800\n",
            "Building X_test j = 2900\n",
            "Building X_test j = 3000\n",
            "Building X_test j = 3100\n",
            "Building X_test j = 3200\n",
            "Building X_test j = 3300\n",
            "Building X_test j = 3400\n",
            "Building X_test j = 3500\n",
            "Building X_test j = 3600\n",
            "Building X_test j = 3700\n",
            "Building X_test j = 3800\n",
            "Building X_test j = 3900\n",
            "Building X_test j = 4000\n",
            "Building X_test j = 4100\n",
            "Building X_test j = 4200\n",
            "Building X_test j = 4300\n",
            "Building X_test j = 4400\n",
            "Building X_test j = 4500\n",
            "Building X_test j = 4600\n",
            "Building X_test j = 4700\n",
            "Building X_test j = 4800\n",
            "Building X_test j = 4900\n",
            "Building X_test j = 5000\n",
            "Building X_test j = 5100\n",
            "Building X_test j = 5200\n",
            "Building X_test j = 5300\n",
            "Building X_test j = 5400\n",
            "Building X_test j = 5500\n",
            "Building X_test j = 5600\n",
            "Building X_test j = 5700\n",
            "Building X_test j = 5800\n",
            "Building X_test j = 5900\n",
            "Building X_test j = 6000\n",
            "Building X_test j = 6100\n",
            "Building X_test j = 6200\n",
            "Building X_test j = 6300\n",
            "Building X_test j = 6400\n",
            "Building X_test j = 6500\n",
            "Building X_test j = 6600\n",
            "Building X_test j = 6700\n",
            "Building X_test j = 6800\n",
            "Building X_test j = 6900\n",
            "Building X_test j = 7000\n",
            "Building X_test j = 7100\n",
            "Building X_test j = 7200\n",
            "Building X_test j = 7300\n",
            "Building X_test j = 7400\n",
            "Building X_test j = 7500\n",
            "Building X_test j = 7600\n",
            "Building X_test j = 7700\n",
            "Building X_test j = 7800\n",
            "Building X_test j = 7900\n",
            "Building X_test j = 8000\n",
            "Building X_test j = 8100\n",
            "Building X_test j = 8200\n",
            "Building X_test j = 8300\n",
            "Building X_test j = 8400\n",
            "Building X_test j = 8500\n",
            "Building X_test j = 8600\n",
            "Building X_test j = 8700\n",
            "Building X_test j = 8800\n",
            "Bulding KERAS models!\n",
            "Training the model!\n",
            "Epoch 1/5\n",
            " 701/1564 [============>.................] - ETA: 2:23:36 - loss: 0.6545 - accuracy: 0.7183"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fyg1AWC4hLG"
      },
      "source": [
        "#Hirarchical Attention\n",
        "\n",
        "import re\n",
        "from itertools import chain\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import GRU, Bidirectional, TimeDistributed, CuDNNLSTM, LSTM, Dropout, CuDNNGRU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import  RMSprop\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FWrEtnU4lLz"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number  to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qObqdKXK4yWE"
      },
      "source": [
        "RNN = CuDNNGRU\n",
        "X, Y = data1\n",
        "\n",
        "enc = LabelEncoder()\n",
        "yc = enc.fit_transform(Y)\n",
        "oh = LabelBinarizer()\n",
        "y_trans = oh.fit_transform(yc)\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words = set([w.translate(translator) for w in stop_words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcVCujyf44th"
      },
      "source": [
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for dataset\n",
        "    Every dataset is lower cased except\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"\\\\\", \"\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "    string = re.sub(r\"\\\"\", \"\", string)\n",
        "    string = string.strip().lower().translate(translator)\n",
        "    return string\n",
        "\n",
        "def remove_stopwords_from_sent(sent):\n",
        "    res = []\n",
        "    for word in sent:\n",
        "        if word not in stop_words:\n",
        "            res.append(word)\n",
        "    return res\n",
        "\n",
        "\n",
        "def build_sentences(X):\n",
        "    X_sentences = []\n",
        "    for doc in X:\n",
        "        sentences = sent_tokenize(doc)\n",
        "        cleaned = map(clean_str, sentences)\n",
        "        tokenized = map(word_tokenize, cleaned)\n",
        "        cleaned = map(remove_stopwords_from_sent, tokenized)\n",
        "        X_sentences.append(list(cleaned))\n",
        "\n",
        "    return X_sentences\n",
        "\n",
        "X_sentences = build_sentences(X)\n",
        "\n",
        "list(map(print, X_sentences[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBqtc0dJ45cc"
      },
      "source": [
        "# Word2vec parameters\n",
        "min_word_frequency_word2vec = 3\n",
        "embed_size_word2vec = 200\n",
        "context_window_word2vec = 5\n",
        "\n",
        "X_merged = list(map(lambda l: list(chain(*l)), X_sentences))\n",
        "\n",
        "print(X_merged[13])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khB9ZdG249nb"
      },
      "source": [
        "wordvec_model = Word2Vec(X_merged, min_count=min_word_frequency_word2vec,\n",
        "                         size=embed_size_word2vec, window=context_window_word2vec)\n",
        "max_doc_len = 5\n",
        "max_sentence_len = 100\n",
        "num = len(X_sentences)\n",
        "\n",
        "vocabulary = wordvec_model.wv.vocab\n",
        "print(\"Vocabulary\", len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRBEYMX05A16"
      },
      "source": [
        "def map_sentence(sent):\n",
        "    out = np.empty((max_sentence_len, embed_size_word2vec))\n",
        "    for ind, word in enumerate(sent):\n",
        "        if ind == max_sentence_len:\n",
        "            break\n",
        "        if word in vocabulary:\n",
        "            out[ind, :] = wordvec_model.wv[word]\n",
        "    return out\n",
        "\n",
        "\n",
        "def map_doc(doc):\n",
        "    out = np.empty((max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "    for ind, sent in enumerate(doc):\n",
        "        if ind == max_doc_len:\n",
        "            break\n",
        "        out[ind, :] = map_sentence(sent)\n",
        "    return out\n",
        "\n",
        "\n",
        "x = np.empty((num, max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "\n",
        "for ind, doc in enumerate(X_sentences):\n",
        "    x[ind, :] = map_doc(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP_cppAU5Fch"
      },
      "source": [
        "def make_model(rnn_dim=64, dense_dim=50):\n",
        "\n",
        "    def attention_block():\n",
        "        def f(input):\n",
        "            rnn = Bidirectional(RNN(rnn_dim, return_sequences=True))(input)\n",
        "            drop1 = Dropout(0.75)(rnn)\n",
        "            dense = TimeDistributed(Dense(dense_dim))(drop1)\n",
        "            drop2 = Dropout(0.6)(dense)\n",
        "            att = AttentionWithContext()(drop2)\n",
        "            return att\n",
        "        return f\n",
        "\n",
        "    with K.name_scope('sentence_enc'):\n",
        "        sentence_input = Input(shape=(max_sentence_len, embed_size_word2vec))\n",
        "        word_att = attention_block()(sentence_input)\n",
        "        sentEncoder = Model(sentence_input, word_att)\n",
        "\n",
        "    with K.name_scope('doc_enc'):\n",
        "        doc_input = Input(shape=(max_doc_len, max_sentence_len, embed_size_word2vec))\n",
        "        sent_enc = TimeDistributed(sentEncoder)(doc_input)\n",
        "        doc_att = attention_block()(sent_enc)\n",
        "        preds = Dense(y_trans.shape[-1], activation='softmax')(doc_att)\n",
        "\n",
        "        model = Model(doc_input, preds)\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQwNbP9X5GJO"
      },
      "source": [
        "model = make_model(rnn_dim=64, dense_dim=64)\n",
        "model.summary()\n",
        "\n",
        "sz = len(y_trans)\n",
        "x_train = x[int(0.1 * sz):int(0.95 * sz)]\n",
        "x_test = np.stack(x[:int(0.1 * sz)], x[int(0.95 * sz):])\n",
        "\n",
        "y_train = y_trans[int(0.1 * sz):int(0.95 * sz)]\n",
        "y_test = np.stack(y_trans[:int(0.1 * sz)], y_trans[int(0.95 * sz):])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFtR0S4o5Im9"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "          epochs=10, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCounoa95Ktv"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def report(x, y):\n",
        "    labels = np.argmax(y, axis=-1)\n",
        "    predicted = np.argmax(model.predict(x), axis=-1)\n",
        "\n",
        "    print(\"Acc\", accuracy_score(labels, predicted))\n",
        "    print(\"F1\", f1_score(labels, predicted, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnqGrf5F5PTg"
      },
      "source": [
        "print(\"Training\")\n",
        "report(x_train, y_train)\n",
        "print(\"Testing\")\n",
        "report(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}